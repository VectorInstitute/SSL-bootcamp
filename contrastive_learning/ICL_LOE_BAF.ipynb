{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "\n",
    "from deepod.models.icl import ICLNet\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ModelSummary,\n",
    "    RichProgressBar,\n",
    ")\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_tabular.config import DataConfig\n",
    "from pytorch_tabular.tabular_datamodule import TabularDatamodule\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 4096\n",
    "SEED = 42\n",
    "\n",
    "if os.environ.get(\"USER\") is not None and os.environ.get(\"SLURM_JOB_ID\") is not None:\n",
    "    CKPT_DIR = f\"/checkpoint/{os.environ['USER']}/{os.environ['SLURM_JOB_ID']}\"\n",
    "    DATA_DIR = \"/ssd003/projects/aieng/public/ssl_bootcamp_resources/datasets/bank_account_fraud_dataset/\"\n",
    "else:  # not on Vector's cluster\n",
    "    CKPT_DIR = \"checkpoint\"\n",
    "    DATA_DIR = \"data\"  # NOTE: download the data from https://www.kaggle.com/datasets/sgpjesus/bank-account-fraud-dataset-neurips-2022\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, \"Base.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = [\n",
    "    \"income\",\n",
    "    \"name_email_similarity\",\n",
    "    \"prev_address_months_count\",\n",
    "    \"current_address_months_count\",\n",
    "    \"customer_age\",\n",
    "    \"days_since_request\",\n",
    "    \"intended_balcon_amount\",\n",
    "    \"zip_count_4w\",\n",
    "    \"velocity_6h\",\n",
    "    \"velocity_24h\",\n",
    "    \"velocity_4w\",\n",
    "    \"bank_branch_count_8w\",\n",
    "    \"date_of_birth_distinct_emails_4w\",\n",
    "    \"credit_risk_score\",\n",
    "    \"bank_months_count\",\n",
    "    \"proposed_credit_limit\",\n",
    "    \"session_length_in_minutes\",\n",
    "    \"device_distinct_emails_8w\",\n",
    "    \"device_fraud_count\",\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    \"payment_type\",\n",
    "    \"employment_status\",\n",
    "    \"housing_status\",\n",
    "    \"device_os\",\n",
    "    \"email_is_free\",\n",
    "    \"phone_home_valid\",\n",
    "    \"phone_mobile_valid\",\n",
    "    \"has_other_cards\",\n",
    "    \"foreign_request\",\n",
    "    \"keep_alive_session\",\n",
    "    \"source\",\n",
    "]\n",
    "\n",
    "target_col = [\"fraud_bool\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_bool</th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>...</th>\n",
       "      <th>phone_mobile_valid_0</th>\n",
       "      <th>phone_mobile_valid_1</th>\n",
       "      <th>has_other_cards_0</th>\n",
       "      <th>has_other_cards_1</th>\n",
       "      <th>foreign_request_0</th>\n",
       "      <th>foreign_request_1</th>\n",
       "      <th>keep_alive_session_0</th>\n",
       "      <th>keep_alive_session_1</th>\n",
       "      <th>source_INTERNET</th>\n",
       "      <th>source_TELEAPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.166828</td>\n",
       "      <td>-1</td>\n",
       "      <td>88</td>\n",
       "      <td>50</td>\n",
       "      <td>0.020925</td>\n",
       "      <td>-1.331345</td>\n",
       "      <td>769</td>\n",
       "      <td>10650.765523</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.296286</td>\n",
       "      <td>-1</td>\n",
       "      <td>144</td>\n",
       "      <td>50</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>-0.816224</td>\n",
       "      <td>366</td>\n",
       "      <td>534.047319</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.044985</td>\n",
       "      <td>-1</td>\n",
       "      <td>132</td>\n",
       "      <td>40</td>\n",
       "      <td>3.108549</td>\n",
       "      <td>-0.755728</td>\n",
       "      <td>870</td>\n",
       "      <td>4048.534263</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.159511</td>\n",
       "      <td>-1</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>0.019079</td>\n",
       "      <td>-1.205124</td>\n",
       "      <td>810</td>\n",
       "      <td>3457.064063</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.596414</td>\n",
       "      <td>-1</td>\n",
       "      <td>218</td>\n",
       "      <td>50</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>-0.773276</td>\n",
       "      <td>890</td>\n",
       "      <td>5020.341679</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fraud_bool  income  name_email_similarity  prev_address_months_count  \\\n",
       "0           1     0.9               0.166828                         -1   \n",
       "1           1     0.9               0.296286                         -1   \n",
       "2           1     0.9               0.044985                         -1   \n",
       "3           1     0.9               0.159511                         -1   \n",
       "4           1     0.9               0.596414                         -1   \n",
       "\n",
       "   current_address_months_count  customer_age  days_since_request  \\\n",
       "0                            88            50            0.020925   \n",
       "1                           144            50            0.005418   \n",
       "2                           132            40            3.108549   \n",
       "3                            22            50            0.019079   \n",
       "4                           218            50            0.004441   \n",
       "\n",
       "   intended_balcon_amount  zip_count_4w   velocity_6h  ...  \\\n",
       "0               -1.331345           769  10650.765523  ...   \n",
       "1               -0.816224           366    534.047319  ...   \n",
       "2               -0.755728           870   4048.534263  ...   \n",
       "3               -1.205124           810   3457.064063  ...   \n",
       "4               -0.773276           890   5020.341679  ...   \n",
       "\n",
       "   phone_mobile_valid_0  phone_mobile_valid_1  has_other_cards_0  \\\n",
       "0                  True                 False               True   \n",
       "1                  True                 False               True   \n",
       "2                 False                  True               True   \n",
       "3                 False                  True              False   \n",
       "4                  True                 False               True   \n",
       "\n",
       "   has_other_cards_1  foreign_request_0  foreign_request_1  \\\n",
       "0              False               True              False   \n",
       "1              False               True              False   \n",
       "2              False               True              False   \n",
       "3               True               True              False   \n",
       "4              False               True              False   \n",
       "\n",
       "   keep_alive_session_0  keep_alive_session_1  source_INTERNET  source_TELEAPP  \n",
       "0                  True                 False             True           False  \n",
       "1                  True                 False             True           False  \n",
       "2                  True                 False             True           False  \n",
       "3                  True                 False             True           False  \n",
       "4                 False                  True             True           False  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encode categorical columns in for loop\n",
    "df_concat_lst = []\n",
    "for col in categorical_cols:\n",
    "    one_hot = pd.get_dummies(df[col], prefix=col)\n",
    "    df = df.drop(col, axis=1)\n",
    "    df_concat_lst.append(one_hot)\n",
    "\n",
    "df = pd.concat([df] + df_concat_lst, axis=1)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['payment_type_AA', 'payment_type_AB', 'payment_type_AC', 'payment_type_AD', 'payment_type_AE', 'employment_status_CA', 'employment_status_CB', 'employment_status_CC', 'employment_status_CD', 'employment_status_CE', 'employment_status_CF', 'employment_status_CG', 'housing_status_BA', 'housing_status_BB', 'housing_status_BC', 'housing_status_BD', 'housing_status_BE', 'housing_status_BF', 'housing_status_BG', 'device_os_linux', 'device_os_macintosh', 'device_os_other', 'device_os_windows', 'device_os_x11', 'email_is_free_0', 'email_is_free_1', 'phone_home_valid_0', 'phone_home_valid_1', 'phone_mobile_valid_0', 'phone_mobile_valid_1', 'has_other_cards_0', 'has_other_cards_1', 'foreign_request_0', 'foreign_request_1', 'keep_alive_session_0', 'keep_alive_session_1', 'source_INTERNET', 'source_TELEAPP']\n"
     ]
    }
   ],
   "source": [
    "# update the categorical columns\n",
    "categorical_cols = [\n",
    "    col for col in df.columns if col.startswith(tuple(categorical_cols))\n",
    "]\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_df, test_df = train_test_split(\n",
    "#     df, test_size=0.2, random_state=SEED, stratify=df[target_col]\n",
    "# )\n",
    "\n",
    "# drop the month column, but keep it for later\n",
    "month = df[\"month\"].values\n",
    "df = df.drop(columns=[\"month\"])\n",
    "\n",
    "# select the first 6 months of data for training and the last 2 months for testing\n",
    "train_df = df[month <= 6]\n",
    "test_df = df[month > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfg = DataConfig(\n",
    "    target=target_col,\n",
    "    continuous_cols=continuous_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    continuous_feature_transform=None,\n",
    "    normalize_continuous_features=True,\n",
    "    validation_split=0.3,\n",
    ")\n",
    "data_cfg = OmegaConf.structured(data_cfg)\n",
    "\n",
    "cfg = OmegaConf.merge(\n",
    "    OmegaConf.to_container(data_cfg),\n",
    "    OmegaConf.create(\n",
    "        {\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"task\": \"classification\",\n",
    "            \"num_workers\": 4,\n",
    "            \"pin_memory\": True,\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "data = TabularDatamodule(\n",
    "    train=train_df,\n",
    "    config=cfg,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICLModule(LightningModule):\n",
    "    \"\"\"Lightning module for ICL model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_features : int\n",
    "        The number of features in the data.\n",
    "    rep_dim : int, optional, default=128\n",
    "        The dimension of the representation.\n",
    "    hidden_dims : str, optional, default=\"100,50\"\n",
    "        The number of hidden units in each layer of the encoders.\n",
    "    lr : float, optional, default=1e-3\n",
    "        The learning rate.\n",
    "    act : str, optional, default=\"LeakyReLU\"\n",
    "        The activation function.\n",
    "    bias : bool, optional, default=False\n",
    "        Whether to use bias in the encoders.\n",
    "    kernel_size : int or str, optional, default=\"auto\"\n",
    "        The kernel size of the sliding window.\n",
    "    temperature : float, optional, default=0.01\n",
    "        The temperature parameter for the softmax function.\n",
    "    max_negatives : int, optional, default=1000\n",
    "        The maximum number of negative samples.\n",
    "    contamination : float, optional, default=0.01\n",
    "        The contamination rate.\n",
    "    train_method : str, optional, default=\"loe_hard\"\n",
    "        The training method. Choose from \"blind\", \"loe_hard\", \"loe_soft\", \"refine\", or \"gt\".\n",
    "        - \"blind\": train the model without any labels.\n",
    "        - \"loe_hard\": train the model with the hard labels from the LOE.\n",
    "        - \"loe_soft\": train the model with the soft labels from the LOE.\n",
    "        - \"refine\": use the loss on the normal samples to rank the samples and\n",
    "            select the top (1 - contamination) as anomalies.\n",
    "        - \"gt\": use the ground truth labels to train the model.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        rep_dim: int = 128,\n",
    "        hidden_dims: list = [128, 64],\n",
    "        lr: float = 1e-3,\n",
    "        act: str = \"LeakyReLU\",\n",
    "        bias: bool = False,\n",
    "        kernel_size: Union[int, str] = \"auto\",\n",
    "        temperature: float = 0.01,\n",
    "        max_negatives: int = 1000,\n",
    "        contamination: float = 0.01,\n",
    "        train_method: Literal[\n",
    "            \"blind\", \"loe_hard\", \"loe_soft\", \"refine\", \"gt\"\n",
    "        ] = \"loe_hard\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        assert train_method in [\n",
    "            \"blind\",\n",
    "            \"loe_hard\",\n",
    "            \"loe_soft\",\n",
    "            \"refine\",\n",
    "            \"gt\",\n",
    "        ], \"Unknown training method. Please choose from 'blind', 'loe_hard', 'loe_soft', 'refine', or 'gt'.\"\n",
    "\n",
    "        if n_features < 3:\n",
    "            raise ValueError(\n",
    "                \"ICL model cannot handle the data that have less than three features.\"\n",
    "            )\n",
    "\n",
    "        if kernel_size == \"auto\":\n",
    "            if n_features < 40:\n",
    "                kernel_size = 2\n",
    "            elif 40 <= n_features <= 160:\n",
    "                kernel_size = 10\n",
    "            elif 160 < n_features <= 240:\n",
    "                kernel_size = n_features - 150\n",
    "            elif 240 < n_features <= 480:\n",
    "                kernel_size = n_features - 200\n",
    "            else:\n",
    "                kernel_size = n_features - 400\n",
    "\n",
    "        print(\"Number of features:\", n_features)\n",
    "        print(\"Kernel size:\", kernel_size)\n",
    "\n",
    "        self.model = ICLNet(\n",
    "            n_features=n_features,\n",
    "            kernel_size=kernel_size,\n",
    "            hidden_dims=hidden_dims,\n",
    "            rep_dim=rep_dim,\n",
    "            activation=act,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        self.contamination = contamination\n",
    "        self.train_method = train_method\n",
    "        self.max_negatives = max_negatives\n",
    "        self.tau = temperature\n",
    "\n",
    "        self.auroc = BinaryAUROC(thresholds=10)\n",
    "        self.f1_score = BinaryF1Score(threshold=0.5)\n",
    "\n",
    "    def _cal_logit(self, query: torch.Tensor, pos: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Calculate the logits for the query and positive samples.\"\"\"\n",
    "        n_pos = query.shape[1]\n",
    "        batch_size = query.shape[0]\n",
    "\n",
    "        # get negatives\n",
    "        negative_index = np.random.choice(\n",
    "            np.arange(n_pos), min(self.max_negatives, n_pos), replace=False\n",
    "        )\n",
    "        negative = pos.permute(0, 2, 1)[:, :, negative_index]\n",
    "\n",
    "        pos_multiplication = (query * pos).sum(dim=2).unsqueeze(2)\n",
    "\n",
    "        neg_multiplication = torch.matmul(query, negative)  # [batch_size, n_neg, n_neg]\n",
    "\n",
    "        # Removal of the diagonals\n",
    "        identity_matrix = torch.eye(n_pos).unsqueeze(0).to(self.device)\n",
    "        identity_matrix = identity_matrix.repeat(batch_size, 1, 1)\n",
    "        identity_matrix = identity_matrix[:, :, negative_index]\n",
    "\n",
    "        neg_multiplication.masked_fill_(identity_matrix == 1, -float(\"inf\"))\n",
    "\n",
    "        logit = torch.cat((pos_multiplication, neg_multiplication), dim=2)\n",
    "        logit = torch.div(logit, self.tau)\n",
    "\n",
    "        return logit\n",
    "\n",
    "    def forward(self, batch: dict, loss_reduction: str = \"mean\") -> torch.Tensor:\n",
    "        \"\"\"Run forward pass.\"\"\"\n",
    "        # combine batch['continuous'] and batch['categorical'] into x\n",
    "        cont_x = batch[\"continuous\"]\n",
    "        cat_x = batch[\"categorical\"]\n",
    "        x = torch.cat((cont_x, cat_x), dim=1)\n",
    "\n",
    "        # positives are sub-vectors, query are their complements\n",
    "        # shape: [batch_size, n_features - 1, rep_dim]\n",
    "        positives, query = self.model(x.float())\n",
    "\n",
    "        logit = self._cal_logit(query, positives)\n",
    "        logit = logit.permute(0, 2, 1)  # [batch_size, n_pos, n_pos - 1]\n",
    "\n",
    "        correct_class = torch.zeros(\n",
    "            (logit.shape[0], logit.shape[2]), dtype=torch.long\n",
    "        ).to(self.device)\n",
    "\n",
    "        loss_n = F.cross_entropy(logit.float(), correct_class, reduction=loss_reduction)\n",
    "\n",
    "        complement_of_logit = torch.where(logit == float(\"-inf\"), logit, 1 - logit)\n",
    "        loss_a = F.cross_entropy(\n",
    "            complement_of_logit, correct_class, reduction=loss_reduction\n",
    "        )\n",
    "\n",
    "        return loss_n.float().mean(dim=1), loss_a.float().mean(dim=1)\n",
    "\n",
    "    def _compute_mean_loss(\n",
    "        self, loss_n: torch.Tensor, loss_a: torch.Tensor, labels: torch.Tensor = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Compute the loss based on the training method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        loss_n : torch.Tensor\n",
    "            The loss on the normal samples.\n",
    "        loss_a : torch.Tensor\n",
    "            The loss on the anomaly samples.\n",
    "        labels : torch.Tensor, optional, default=None\n",
    "            The ground truth labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : torch.Tensor\n",
    "            The loss.\n",
    "        \"\"\"\n",
    "        score = loss_n - loss_a\n",
    "\n",
    "        if self.train_method == \"blind\":\n",
    "            loss = loss_n.mean()\n",
    "        elif self.train_method == \"loe_hard\":\n",
    "            _, idx_n = torch.topk(\n",
    "                score,\n",
    "                int(score.shape[0] * (1 - self.contamination)),\n",
    "                largest=False,\n",
    "                sorted=False,\n",
    "            )\n",
    "            _, idx_a = torch.topk(\n",
    "                score,\n",
    "                int(score.shape[0] * self.contamination),\n",
    "                largest=True,\n",
    "                sorted=False,\n",
    "            )\n",
    "            loss = torch.cat([loss_n[idx_n], loss_a[idx_a]], 0).mean()\n",
    "        elif self.train_method == \"loe_soft\":\n",
    "            _, idx_n = torch.topk(\n",
    "                score,\n",
    "                int(score.shape[0] * (1 - self.contamination)),\n",
    "                largest=False,\n",
    "                sorted=False,\n",
    "            )\n",
    "            _, idx_a = torch.topk(\n",
    "                score,\n",
    "                int(score.shape[0] * self.contamination),\n",
    "                largest=True,\n",
    "                sorted=False,\n",
    "            )\n",
    "            loss = torch.cat(\n",
    "                [loss_n[idx_n], 0.5 * loss_n[idx_a] + 0.5 * loss_a[idx_a]], 0\n",
    "            ).mean()\n",
    "        elif self.train_method == \"refine\":\n",
    "            _, idx_n = torch.topk(\n",
    "                loss_n,\n",
    "                int(loss_n.shape[0] * (1 - self.contamination)),\n",
    "                largest=False,\n",
    "                sorted=False,\n",
    "            )\n",
    "            loss = loss_n[idx_n].mean()\n",
    "        elif self.train_method == \"gt\" and labels is not None:\n",
    "            loss = torch.cat([loss_n[labels == 0], loss_a[labels == 1]], 0).mean()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unknown training method: {self.train_method}. \"\n",
    "                \"Please choose from 'blind', 'loe_hard', 'loe_soft', 'refine', \"\n",
    "                \"or 'gt'.\"\n",
    "            )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch: dict, batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Run training step.\"\"\"\n",
    "        loss_n, loss_a = self(batch, loss_reduction=\"none\")\n",
    "        loss = self._compute_mean_loss(loss_n, loss_a, labels=batch[\"target\"])\n",
    "\n",
    "        self.log(\"train/loss\", loss, prog_bar=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: dict, batch_idx: int) -> None:\n",
    "        \"\"\"Run validation step.\"\"\"\n",
    "        loss_n, loss_a = self(batch, loss_reduction=\"none\")\n",
    "        loss = self._compute_mean_loss(loss_n, loss_a, labels=batch[\"target\"])\n",
    "\n",
    "        self.log(\"val/loss\", loss, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        targets = batch[\"target\"].squeeze()\n",
    "\n",
    "        # get the predictions\n",
    "        if self.contamination is None:\n",
    "            self.contamination = targets.float().mean().item()\n",
    "\n",
    "        scores = loss_n - loss_a\n",
    "        threshold = torch.quantile(scores, q=(1 - self.contamination)).to(self.device)\n",
    "        preds = (scores > threshold).long().ravel()\n",
    "\n",
    "        # compute the metrics\n",
    "        self.auroc(preds, targets)\n",
    "        self.log(\"val/auroc\", self.auroc, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        self.f1_score(preds, targets)\n",
    "        self.log(\"val/f1_score\", self.f1_score, prog_bar=True, sync_dist=True)\n",
    "\n",
    "    def test_step(self, batch: dict, batch_idx: int) -> None:\n",
    "        \"\"\"Run test step.\"\"\"\n",
    "        loss_n, loss_a = self(batch, loss_reduction=\"none\")\n",
    "        loss = self._compute_mean_loss(loss_n, loss_a, labels=batch[\"target\"])\n",
    "\n",
    "        self.log(\"test/loss\", loss, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        targets = batch[\"target\"].squeeze()\n",
    "\n",
    "        # get the predictions\n",
    "        if self.contamination is None:\n",
    "            self.contamination = targets.float().mean().item()\n",
    "\n",
    "        scores = loss_n - loss_a\n",
    "        threshold = torch.quantile(scores, q=(1 - self.contamination)).to(self.device)\n",
    "        preds = (scores > threshold).long().ravel()\n",
    "\n",
    "        # compute the metrics\n",
    "        self.auroc(preds, targets)\n",
    "        self.log(\"test/auroc\", self.auroc, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        self.f1_score(preds, targets)\n",
    "        self.log(\"test/f1_score\", self.f1_score, prog_bar=True, sync_dist=True)\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Optimizer:\n",
    "        \"\"\"Configure the optimizer.\"\"\"\n",
    "        return torch.optim.Adam(\n",
    "            self.model.parameters(), lr=self.hparams.lr, weight_decay=1e-5\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"ICL_LOE_BAF.ipynb\"\n",
      "env: WANDB_SILENT=True\n"
     ]
    }
   ],
   "source": [
    "%env \"WANDB_NOTEBOOK_NAME\" \"ICL_LOE_BAF.ipynb\"\n",
    "%env WANDB_SILENT=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 57\n",
      "Kernel size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = ICLModule(\n",
    "    n_features=(len(continuous_cols) + len(categorical_cols)),\n",
    "    train_method=\"loe_hard\",\n",
    "    hidden_dims=[192, 96],\n",
    "    lr=3e-2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    precision=\"16\",\n",
    "    benchmark=True,\n",
    "    max_epochs=-1,\n",
    "    log_every_n_steps=10,\n",
    "    default_root_dir=CKPT_DIR,\n",
    "    # fast_dev_run=100,\n",
    "    callbacks=[\n",
    "        RichProgressBar(),\n",
    "        ModelSummary(max_depth=5),\n",
    "        EarlyStopping(monitor=\"val/loss\", patience=10, stopping_threshold=1e-2),\n",
    "        ModelCheckpoint(\n",
    "            dirpath=CKPT_DIR,\n",
    "            filename=\"ICL-BAF-{epoch:02d}-{val/loss:.2f}\",\n",
    "            monitor=\"val/loss\",\n",
    "            save_top_k=3,\n",
    "            mode=\"min\",\n",
    "        ),\n",
    "    ],\n",
    "    logger=WandbLogger(\n",
    "        project=\"icl-baf\",\n",
    "        name=\"icl-baf-trial-1\",\n",
    "        entity=\"vector-ssl-bootcamp\",\n",
    "        save_dir=CKPT_DIR,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 23:44:38,534 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for classification task\n",
      "/ssd003/projects/aieng/public/ssl_bootcamp_resources/venv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /checkpoint/fogidi/10716275 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                                | Type          | Params\n",
      "-----------------------------------------------------------------------\n",
      "0  | model                               | ICLNet        | 51.5 K\n",
      "1  | model.enc_f_net                     | MLPnet        | 39.7 K\n",
      "2  | model.enc_f_net.network             | Sequential    | 39.7 K\n",
      "3  | model.enc_f_net.network.0           | LinearBlock   | 9.0 K \n",
      "4  | model.enc_f_net.network.0.linear    | Linear        | 9.0 K \n",
      "5  | model.enc_f_net.network.0.act_layer | Tanh          | 0     \n",
      "6  | model.enc_f_net.network.0.bn_layer  | BatchNorm1d   | 0     \n",
      "7  | model.enc_f_net.network.1           | LinearBlock   | 18.4 K\n",
      "8  | model.enc_f_net.network.1.linear    | Linear        | 18.4 K\n",
      "9  | model.enc_f_net.network.1.act_layer | LeakyReLU     | 0     \n",
      "10 | model.enc_f_net.network.1.bn_layer  | BatchNorm1d   | 0     \n",
      "11 | model.enc_f_net.network.2           | LinearBlock   | 12.3 K\n",
      "12 | model.enc_f_net.network.2.linear    | Linear        | 12.3 K\n",
      "13 | model.enc_f_net.network.2.act_layer | LeakyReLU     | 0     \n",
      "14 | model.enc_f_net.network.2.bn_layer  | BatchNorm1d   | 0     \n",
      "15 | model.enc_g_net                     | MLPnet        | 11.7 K\n",
      "16 | model.enc_g_net.network             | Sequential    | 11.7 K\n",
      "17 | model.enc_g_net.network.0           | LinearBlock   | 960   \n",
      "18 | model.enc_g_net.network.0.linear    | Linear        | 960   \n",
      "19 | model.enc_g_net.network.0.act_layer | LeakyReLU     | 0     \n",
      "20 | model.enc_g_net.network.0.bn_layer  | BatchNorm1d   | 0     \n",
      "21 | model.enc_g_net.network.1           | LinearBlock   | 4.6 K \n",
      "22 | model.enc_g_net.network.1.linear    | Linear        | 4.6 K \n",
      "23 | model.enc_g_net.network.1.act_layer | LeakyReLU     | 0     \n",
      "24 | model.enc_g_net.network.1.bn_layer  | BatchNorm1d   | 0     \n",
      "25 | model.enc_g_net.network.2           | LinearBlock   | 6.1 K \n",
      "26 | model.enc_g_net.network.2.linear    | Linear        | 6.1 K \n",
      "27 | model.enc_g_net.network.2.act_layer | LeakyReLU     | 0     \n",
      "28 | model.enc_g_net.network.2.bn_layer  | BatchNorm1d   | 0     \n",
      "29 | auroc                               | BinaryAUROC   | 0     \n",
      "30 | f1_score                            | BinaryF1Score | 0     \n",
      "-----------------------------------------------------------------------\n",
      "51.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.5 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49241dbacd02400380a7fc613835fa03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl_env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
