{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expanded-battle",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we will delve into the comprehensive exploration of the paper titled [\"Anomaly Detection for Tabular Data with Internal Contrastive Learning.\"](https://openreview.net/forum?id=_hszZbt46bT) This paper introduces an innovative approach to anomaly detection by addressing the challenge of identifying out-of-class samples within tabular data, particularly when the data's structural characteristics are not well understood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-brooks",
   "metadata": {},
   "source": [
    "## Masking in ICL\n",
    "\n",
    "The image below illustrates how ICL masks a feature vector for contrastive learning. The underlying learning problem. Given a **sample vector** $x_i$, they consider the **subvector** $a_i^3$ and its **complementary** $b_i^3$. The networks are trained to produce similar embeddings for this pair of vectors, while distancing the embedding of $a_i^{j^{\\prime}}$ for $j^{\\prime} \\neq 3$ from that of $b_i^3$.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1WOfi9boxWG4ET3AKochRS8OaGtDjxmZe\" width=\"500\" aligh=\"center\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mysterious-plain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: copulas in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: matplotlib<4,>=3.4.0 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from copulas) (3.5.3)\n",
      "Requirement already satisfied: scipy<2,>=1.5.4 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from copulas) (1.7.3)\n",
      "Requirement already satisfied: numpy<2,>=1.20.0 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from copulas) (1.21.6)\n",
      "Requirement already satisfied: pandas>=1.1.3 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from copulas) (1.3.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from matplotlib<4,>=3.4.0->copulas) (9.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from matplotlib<4,>=3.4.0->copulas) (2.8.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from matplotlib<4,>=3.4.0->copulas) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from matplotlib<4,>=3.4.0->copulas) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from matplotlib<4,>=3.4.0->copulas) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from matplotlib<4,>=3.4.0->copulas) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from matplotlib<4,>=3.4.0->copulas) (20.9)\n",
      "Requirement already satisfied: typing-extensions in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib<4,>=3.4.0->copulas) (4.7.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from pandas>=1.1.3->copulas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib<4,>=3.4.0->copulas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyod in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: six in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from pyod) (1.15.0)\n",
      "Requirement already satisfied: numba>=0.51 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from pyod) (0.56.4)\n",
      "Requirement already satisfied: joblib in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from pyod) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from pyod) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.5.1 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from pyod) (1.7.3)\n",
      "Requirement already satisfied: matplotlib in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from pyod) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.19 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from pyod) (1.21.6)\n",
      "Requirement already satisfied: importlib-metadata in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from numba>=0.51->pyod) (6.7.0)\n",
      "Requirement already satisfied: setuptools in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from numba>=0.51->pyod) (49.6.0.post20210108)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from numba>=0.51->pyod) (0.39.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from scikit-learn>=0.22.0->pyod) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from importlib-metadata->numba>=0.51->pyod) (4.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from importlib-metadata->numba>=0.51->pyod) (3.4.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from matplotlib->pyod) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from matplotlib->pyod) (9.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from matplotlib->pyod) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from matplotlib->pyod) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /scratch/ssd001/pkgs/jupyterhub/lib/python3.7/site-packages (from matplotlib->pyod) (2.8.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from matplotlib->pyod) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /fs01/home/mpourreza/.local/lib/python3.7/site-packages (from matplotlib->pyod) (1.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ruff: noqa\n",
    "# type: ignore\n",
    "\"\"\" Installing packages and importing libs.\n",
    "Installing requirements and import files\n",
    "\"\"\"\n",
    "\n",
    "%pip install pandas\n",
    "%pip install copulas\n",
    "%pip install pyod\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from data_generator import DataGenerator\n",
    "from myutils import Utils\n",
    "from deepod.models.icl import ICL\n",
    "from pyod_base import PYOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-navigator",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "In this part, we will work with the [\"Outlier Detection DataSets (ODDS)\"](https://odds.cs.stonybrook.edu/) dataset, a widely-used benchmark collection of datasets specifically designed for evaluating outlier detection algorithms. The ODDS dataset encompasses a diverse range of data types, structures, and characteristics, making it an ideal choice for assessing the effectiveness of anomaly detection methodologies. In the next cell we see all the datasets are reachable via ODDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "capital-holocaust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3_backdoor.npz',\n",
       " '12_fault.npz',\n",
       " '9_census.npz',\n",
       " '41_Waveform.npz',\n",
       " '36_speech.npz',\n",
       " '21_Lymphography.npz',\n",
       " '23_mammography.npz',\n",
       " '15_Hepatitis.npz',\n",
       " '44_Wilt.npz',\n",
       " '29_Pima.npz',\n",
       " '35_SpamBase.npz',\n",
       " '26_optdigits.npz',\n",
       " '13_fraud.npz',\n",
       " '18_Ionosphere.npz',\n",
       " '34_smtp.npz',\n",
       " '8_celeba.npz',\n",
       " '22_magic.gamma.npz',\n",
       " '6_cardio.npz',\n",
       " '1_ALOI.npz',\n",
       " '10_cover.npz',\n",
       " '20_letter.npz',\n",
       " '47_yeast.npz',\n",
       " '24_mnist.npz',\n",
       " '46_WPBC.npz',\n",
       " '42_WBC.npz',\n",
       " '2_annthyroid.npz',\n",
       " '39_vertebral.npz',\n",
       " '28_pendigits.npz',\n",
       " '30_satellite.npz',\n",
       " '43_WDBC.npz',\n",
       " '31_satimage-2.npz',\n",
       " '27_PageBlocks.npz',\n",
       " '16_http.npz',\n",
       " '33_skin.npz',\n",
       " '4_breastw.npz',\n",
       " '32_shuttle.npz',\n",
       " '11_donors.npz',\n",
       " '25_musk.npz',\n",
       " '19_landsat.npz',\n",
       " '45_wine.npz',\n",
       " '14_glass.npz',\n",
       " '17_InternetAds.npz',\n",
       " '40_vowels.npz',\n",
       " '38_thyroid.npz',\n",
       " '5_campaign.npz',\n",
       " '7_Cardiotocography.npz',\n",
       " '37_Stamps.npz']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagenerator = DataGenerator()  # data generator\n",
    "utils = Utils()  # utils function\n",
    "os.listdir(\"datasets/Classical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baking-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = [\n",
    "    \"6_cardio\",\n",
    "    \"13_fraud\",\n",
    "    \"24_mnist\",\n",
    "    \"42_WBC\",\n",
    "    \"43_WDBC\",\n",
    "    \"4_breastw\",\n",
    "    \"25_musk\",\n",
    "    \"40_vowels\",\n",
    "    \"38_thyroid\",\n",
    "]  # choosing the datasets\n",
    "model_dict = {\"ICL\": PYOD}  # choosing the model\n",
    "\n",
    "# save the results\n",
    "df_AUCROC = pd.DataFrame(data=None, index=dataset_list, columns=model_dict.keys())\n",
    "df_AUCPR = pd.DataFrame(data=None, index=dataset_list, columns=model_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greatest-steps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current noise type: None\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 4\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=19, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 23.454694, time: 1.9s\n",
      "epoch 10, training loss: 2.410294, time: 0.1s\n",
      "epoch 20, training loss: 1.926891, time: 0.2s\n",
      "epoch 30, training loss: 2.073260, time: 0.1s\n",
      "epoch 40, training loss: 1.346864, time: 0.1s\n",
      "epoch 50, training loss: 1.456022, time: 0.1s\n",
      "epoch 60, training loss: 0.999825, time: 0.1s\n",
      "epoch 70, training loss: 1.133194, time: 0.2s\n",
      "epoch 80, training loss: 1.450800, time: 0.1s\n",
      "epoch 90, training loss: 1.119740, time: 0.1s\n",
      "epoch100, training loss: 1.123200, time: 0.2s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=19, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 23.668191, time: 0.1s\n",
      "epoch 10, training loss: 2.618489, time: 0.1s\n",
      "epoch 20, training loss: 1.803053, time: 0.1s\n",
      "epoch 30, training loss: 1.450072, time: 0.1s\n",
      "epoch 40, training loss: 1.386179, time: 0.1s\n",
      "epoch 50, training loss: 1.141813, time: 0.1s\n",
      "epoch 60, training loss: 1.362055, time: 0.2s\n",
      "epoch 70, training loss: 1.165161, time: 0.1s\n",
      "epoch 80, training loss: 1.570335, time: 0.1s\n",
      "epoch 90, training loss: 1.130047, time: 0.1s\n",
      "epoch100, training loss: 1.282426, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=19, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 24.370721, time: 0.1s\n",
      "epoch 10, training loss: 2.715386, time: 0.1s\n",
      "epoch 20, training loss: 1.708555, time: 0.1s\n",
      "epoch 30, training loss: 1.403677, time: 0.1s\n",
      "epoch 40, training loss: 1.281717, time: 0.2s\n",
      "epoch 50, training loss: 1.189191, time: 0.1s\n",
      "epoch 60, training loss: 1.089853, time: 0.1s\n",
      "epoch 70, training loss: 1.223911, time: 0.1s\n",
      "epoch 80, training loss: 1.047861, time: 0.1s\n",
      "epoch 90, training loss: 1.054045, time: 0.1s\n",
      "epoch100, training loss: 1.026316, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=19, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 22.401813, time: 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 2.456641, time: 0.1s\n",
      "epoch 20, training loss: 1.718342, time: 0.2s\n",
      "epoch 30, training loss: 1.969649, time: 0.1s\n",
      "epoch 40, training loss: 1.387178, time: 0.1s\n",
      "epoch 50, training loss: 1.321773, time: 0.1s\n",
      "epoch 60, training loss: 1.184589, time: 0.1s\n",
      "epoch 70, training loss: 1.262119, time: 0.1s\n",
      "epoch 80, training loss: 1.176873, time: 0.1s\n",
      "epoch 90, training loss: 1.132189, time: 0.1s\n",
      "epoch100, training loss: 1.130423, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 21/21 [00:00<00:00, 367.72it/s]\n",
      "testing: 100%|██████████| 21/21 [00:00<00:00, 377.23it/s]\n",
      "testing: 100%|██████████| 21/21 [00:00<00:00, 376.37it/s]\n",
      "testing: 100%|██████████| 21/21 [00:00<00:00, 380.26it/s]\n",
      "testing: 100%|██████████| 9/9 [00:00<00:00, 353.30it/s]\n",
      "testing: 100%|██████████| 9/9 [00:00<00:00, 366.42it/s]\n",
      "testing: 100%|██████████| 9/9 [00:00<00:00, 295.28it/s]\n",
      "testing: 100%|██████████| 9/9 [00:00<00:00, 322.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsampling for dataset 13_fraud...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 16, 'Anomalies Ratio(%)': 0.16}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=27, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 4.148517, time: 0.8s\n",
      "epoch 10, training loss: 2.093605, time: 0.8s\n",
      "epoch 20, training loss: 1.755030, time: 0.8s\n",
      "epoch 30, training loss: 1.487752, time: 0.8s\n",
      "epoch 40, training loss: 1.292715, time: 0.8s\n",
      "epoch 50, training loss: 1.053313, time: 0.8s\n",
      "epoch 60, training loss: 0.966508, time: 0.8s\n",
      "epoch 70, training loss: 0.856006, time: 0.8s\n",
      "epoch 80, training loss: 0.936475, time: 0.8s\n",
      "epoch 90, training loss: 0.745442, time: 0.8s\n",
      "epoch100, training loss: 0.750319, time: 0.8s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=27, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 5.554015, time: 0.8s\n",
      "epoch 10, training loss: 1.810795, time: 0.8s\n",
      "epoch 20, training loss: 1.425073, time: 0.8s\n",
      "epoch 30, training loss: 1.134234, time: 0.8s\n",
      "epoch 40, training loss: 0.945306, time: 0.8s\n",
      "epoch 50, training loss: 0.799565, time: 0.7s\n",
      "epoch 60, training loss: 0.755849, time: 0.8s\n",
      "epoch 70, training loss: 0.653477, time: 0.8s\n",
      "epoch 80, training loss: 0.669582, time: 0.8s\n",
      "epoch 90, training loss: 0.567222, time: 0.8s\n",
      "epoch100, training loss: 0.523404, time: 0.8s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=27, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 4.439934, time: 0.8s\n",
      "epoch 10, training loss: 1.751113, time: 0.8s\n",
      "epoch 20, training loss: 1.329372, time: 0.8s\n",
      "epoch 30, training loss: 1.202113, time: 0.7s\n",
      "epoch 40, training loss: 1.530806, time: 0.8s\n",
      "epoch 50, training loss: 0.846095, time: 0.7s\n",
      "epoch 60, training loss: 0.757834, time: 0.7s\n",
      "epoch 70, training loss: 0.681858, time: 0.7s\n",
      "epoch 80, training loss: 0.642864, time: 0.8s\n",
      "epoch 90, training loss: 0.628892, time: 0.8s\n",
      "epoch100, training loss: 0.571980, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 110/110 [00:00<00:00, 363.80it/s]\n",
      "testing: 100%|██████████| 110/110 [00:00<00:00, 364.06it/s]\n",
      "testing: 100%|██████████| 110/110 [00:00<00:00, 361.36it/s]\n",
      "testing: 100%|██████████| 47/47 [00:00<00:00, 335.04it/s]\n",
      "testing: 100%|██████████| 47/47 [00:00<00:00, 362.56it/s]\n",
      "testing: 100%|██████████| 47/47 [00:00<00:00, 351.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current noise type: None\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=90, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 7.235302, time: 0.7s\n",
      "epoch 10, training loss: 2.697678, time: 0.6s\n",
      "epoch 20, training loss: 2.173014, time: 0.6s\n",
      "epoch 30, training loss: 1.838425, time: 0.6s\n",
      "epoch 40, training loss: 1.809295, time: 0.6s\n",
      "epoch 50, training loss: 1.564143, time: 0.6s\n",
      "epoch 60, training loss: 1.489870, time: 0.6s\n",
      "epoch 70, training loss: 1.436201, time: 0.6s\n",
      "epoch 80, training loss: 1.401334, time: 0.6s\n",
      "epoch 90, training loss: 1.435534, time: 0.6s\n",
      "epoch100, training loss: 1.377018, time: 0.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 84/84 [00:00<00:00, 334.60it/s]\n",
      "testing: 100%|██████████| 36/36 [00:00<00:00, 335.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 42_WBC...\n",
      "current noise type: None\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 7\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 81.311814, time: 0.1s\n",
      "epoch 10, training loss: 5.868455, time: 0.1s\n",
      "epoch 20, training loss: 4.123191, time: 0.1s\n",
      "epoch 30, training loss: 3.336899, time: 0.1s\n",
      "epoch 40, training loss: 2.120764, time: 0.1s\n",
      "epoch 50, training loss: 2.268210, time: 0.1s\n",
      "epoch 60, training loss: 1.714451, time: 0.1s\n",
      "epoch 70, training loss: 1.707119, time: 0.1s\n",
      "epoch 80, training loss: 1.526228, time: 0.1s\n",
      "epoch 90, training loss: 1.148954, time: 0.1s\n",
      "epoch100, training loss: 1.380639, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 90.114492, time: 0.1s\n",
      "epoch 10, training loss: 8.879294, time: 0.1s\n",
      "epoch 20, training loss: 4.992617, time: 0.1s\n",
      "epoch 30, training loss: 4.167034, time: 0.1s\n",
      "epoch 40, training loss: 3.561490, time: 0.1s\n",
      "epoch 50, training loss: 3.234136, time: 0.1s\n",
      "epoch 60, training loss: 2.999345, time: 0.1s\n",
      "epoch 70, training loss: 2.619627, time: 0.1s\n",
      "epoch 80, training loss: 2.204422, time: 0.1s\n",
      "epoch 90, training loss: 2.158410, time: 0.1s\n",
      "epoch100, training loss: 1.963137, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 88.683979, time: 0.1s\n",
      "epoch 10, training loss: 8.600296, time: 0.1s\n",
      "epoch 20, training loss: 4.665760, time: 0.1s\n",
      "epoch 30, training loss: 4.449682, time: 0.1s\n",
      "epoch 40, training loss: 3.301830, time: 0.1s\n",
      "epoch 50, training loss: 2.686963, time: 0.1s\n",
      "epoch 60, training loss: 2.537857, time: 0.1s\n",
      "epoch 70, training loss: 2.345593, time: 0.1s\n",
      "epoch 80, training loss: 2.126733, time: 0.1s\n",
      "epoch 90, training loss: 1.602416, time: 0.1s\n",
      "epoch100, training loss: 1.498221, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 82.276892, time: 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 7.460176, time: 0.1s\n",
      "epoch 20, training loss: 4.514318, time: 0.1s\n",
      "epoch 30, training loss: 3.253325, time: 0.1s\n",
      "epoch 40, training loss: 2.597877, time: 0.1s\n",
      "epoch 50, training loss: 2.775661, time: 0.1s\n",
      "epoch 60, training loss: 2.399912, time: 0.1s\n",
      "epoch 70, training loss: 2.188711, time: 0.1s\n",
      "epoch 80, training loss: 2.147900, time: 0.1s\n",
      "epoch 90, training loss: 1.657577, time: 0.1s\n",
      "epoch100, training loss: 1.558133, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 74.382610, time: 0.1s\n",
      "epoch 10, training loss: 7.266660, time: 0.1s\n",
      "epoch 20, training loss: 4.702162, time: 0.1s\n",
      "epoch 30, training loss: 3.426771, time: 0.1s\n",
      "epoch 40, training loss: 2.973962, time: 0.1s\n",
      "epoch 50, training loss: 2.508278, time: 0.1s\n",
      "epoch 60, training loss: 2.291205, time: 0.1s\n",
      "epoch 70, training loss: 1.822697, time: 0.1s\n",
      "epoch 80, training loss: 2.096061, time: 0.1s\n",
      "epoch 90, training loss: 1.803747, time: 0.1s\n",
      "epoch100, training loss: 1.572442, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 79.767039, time: 0.1s\n",
      "epoch 10, training loss: 7.490852, time: 0.1s\n",
      "epoch 20, training loss: 5.126416, time: 0.1s\n",
      "epoch 30, training loss: 3.717030, time: 0.1s\n",
      "epoch 40, training loss: 2.779491, time: 0.1s\n",
      "epoch 50, training loss: 2.408553, time: 0.1s\n",
      "epoch 60, training loss: 3.025280, time: 0.1s\n",
      "epoch 70, training loss: 2.048965, time: 0.1s\n",
      "epoch 80, training loss: 2.042275, time: 0.1s\n",
      "epoch 90, training loss: 1.698562, time: 0.1s\n",
      "epoch100, training loss: 1.505450, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 71.979254, time: 0.1s\n",
      "epoch 10, training loss: 7.881646, time: 0.1s\n",
      "epoch 20, training loss: 4.491094, time: 0.1s\n",
      "epoch 30, training loss: 4.482272, time: 0.1s\n",
      "epoch 40, training loss: 3.550430, time: 0.1s\n",
      "epoch 50, training loss: 2.983251, time: 0.1s\n",
      "epoch 60, training loss: 2.719300, time: 0.1s\n",
      "epoch 70, training loss: 2.189467, time: 0.1s\n",
      "epoch 80, training loss: 2.104519, time: 0.1s\n",
      "epoch 90, training loss: 1.685877, time: 0.1s\n",
      "epoch100, training loss: 1.951537, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 11/11 [00:00<00:00, 386.95it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 398.80it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 316.58it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 374.18it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 412.07it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 404.08it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 381.30it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 363.41it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 357.80it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 370.80it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 346.85it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 363.06it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 351.98it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 398.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 43_WDBC...\n",
      "current noise type: None\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 33, 'Anomalies Ratio(%)': 3.3}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=28, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 20.361142, time: 0.1s\n",
      "epoch 10, training loss: 3.233239, time: 0.1s\n",
      "epoch 20, training loss: 2.764909, time: 0.1s\n",
      "epoch 30, training loss: 2.518829, time: 0.1s\n",
      "epoch 40, training loss: 2.390741, time: 0.1s\n",
      "epoch 50, training loss: 2.285093, time: 0.1s\n",
      "epoch 60, training loss: 2.185232, time: 0.1s\n",
      "epoch 70, training loss: 2.116009, time: 0.1s\n",
      "epoch 80, training loss: 2.024424, time: 0.1s\n",
      "epoch 90, training loss: 2.094420, time: 0.1s\n",
      "epoch100, training loss: 2.003311, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=28, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 23.768150, time: 0.1s\n",
      "epoch 10, training loss: 3.544331, time: 0.1s\n",
      "epoch 20, training loss: 2.908149, time: 0.1s\n",
      "epoch 30, training loss: 2.681915, time: 0.1s\n",
      "epoch 40, training loss: 2.585751, time: 0.1s\n",
      "epoch 50, training loss: 2.449894, time: 0.1s\n",
      "epoch 60, training loss: 2.412442, time: 0.1s\n",
      "epoch 70, training loss: 2.361201, time: 0.1s\n",
      "epoch 80, training loss: 2.230608, time: 0.1s\n",
      "epoch 90, training loss: 2.193296, time: 0.1s\n",
      "epoch100, training loss: 2.114835, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=28, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 24.010204, time: 0.1s\n",
      "epoch 10, training loss: 3.254895, time: 0.1s\n",
      "epoch 20, training loss: 2.819153, time: 0.1s\n",
      "epoch 30, training loss: 2.570817, time: 0.1s\n",
      "epoch 40, training loss: 2.484141, time: 0.1s\n",
      "epoch 50, training loss: 2.341665, time: 0.1s\n",
      "epoch 60, training loss: 2.270003, time: 0.1s\n",
      "epoch 70, training loss: 2.222890, time: 0.1s\n",
      "epoch 80, training loss: 2.127623, time: 0.1s\n",
      "epoch 90, training loss: 2.087237, time: 0.1s\n",
      "epoch100, training loss: 2.006832, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 11/11 [00:00<00:00, 337.40it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 328.56it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 354.18it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 315.07it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 323.37it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 316.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 4_breastw...\n",
      "current noise type: None\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 360, 'Anomalies Ratio(%)': 36.0}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 7\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1, training loss: 67.960076, time: 0.1s\n",
      "epoch 10, training loss: 5.922819, time: 0.1s\n",
      "epoch 20, training loss: 4.512699, time: 0.1s\n",
      "epoch 30, training loss: 2.826114, time: 0.1s\n",
      "epoch 40, training loss: 2.110901, time: 0.1s\n",
      "epoch 50, training loss: 1.642380, time: 0.1s\n",
      "epoch 60, training loss: 1.608773, time: 0.1s\n",
      "epoch 70, training loss: 1.415740, time: 0.1s\n",
      "epoch 80, training loss: 1.408265, time: 0.1s\n",
      "epoch 90, training loss: 1.284295, time: 0.1s\n",
      "epoch100, training loss: 1.084434, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 71.475224, time: 0.1s\n",
      "epoch 10, training loss: 8.259924, time: 0.1s\n",
      "epoch 20, training loss: 4.709119, time: 0.1s\n",
      "epoch 30, training loss: 3.464675, time: 0.1s\n",
      "epoch 40, training loss: 3.219796, time: 0.1s\n",
      "epoch 50, training loss: 2.817601, time: 0.1s\n",
      "epoch 60, training loss: 1.846856, time: 0.1s\n",
      "epoch 70, training loss: 1.982103, time: 0.1s\n",
      "epoch 80, training loss: 1.743389, time: 0.1s\n",
      "epoch 90, training loss: 1.800021, time: 0.1s\n",
      "epoch100, training loss: 1.429291, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 69.222926, time: 0.1s\n",
      "epoch 10, training loss: 7.431498, time: 0.1s\n",
      "epoch 20, training loss: 4.150641, time: 0.1s\n",
      "epoch 30, training loss: 3.139024, time: 0.1s\n",
      "epoch 40, training loss: 2.671262, time: 0.1s\n",
      "epoch 50, training loss: 2.416335, time: 0.1s\n",
      "epoch 60, training loss: 1.908183, time: 0.1s\n",
      "epoch 70, training loss: 1.845262, time: 0.1s\n",
      "epoch 80, training loss: 1.692602, time: 0.1s\n",
      "epoch 90, training loss: 1.561762, time: 0.1s\n",
      "epoch100, training loss: 1.598464, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 62.927482, time: 0.1s\n",
      "epoch 10, training loss: 6.420014, time: 0.1s\n",
      "epoch 20, training loss: 3.408841, time: 0.1s\n",
      "epoch 30, training loss: 2.755921, time: 0.1s\n",
      "epoch 40, training loss: 2.065221, time: 0.1s\n",
      "epoch 50, training loss: 2.042411, time: 0.1s\n",
      "epoch 60, training loss: 1.887201, time: 0.1s\n",
      "epoch 70, training loss: 1.399920, time: 0.1s\n",
      "epoch 80, training loss: 1.400338, time: 0.1s\n",
      "epoch 90, training loss: 1.298294, time: 0.1s\n",
      "epoch100, training loss: 1.135850, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 62.099452, time: 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 7.010805, time: 0.1s\n",
      "epoch 20, training loss: 4.063835, time: 0.1s\n",
      "epoch 30, training loss: 3.150791, time: 0.1s\n",
      "epoch 40, training loss: 2.122366, time: 0.1s\n",
      "epoch 50, training loss: 2.116168, time: 0.1s\n",
      "epoch 60, training loss: 1.786091, time: 0.1s\n",
      "epoch 70, training loss: 1.661699, time: 0.1s\n",
      "epoch 80, training loss: 1.374450, time: 0.1s\n",
      "epoch 90, training loss: 1.266468, time: 0.1s\n",
      "epoch100, training loss: 1.407918, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 67.376121, time: 0.1s\n",
      "epoch 10, training loss: 6.547023, time: 0.1s\n",
      "epoch 20, training loss: 3.504931, time: 0.1s\n",
      "epoch 30, training loss: 2.585038, time: 0.1s\n",
      "epoch 40, training loss: 2.321986, time: 0.1s\n",
      "epoch 50, training loss: 1.773794, time: 0.1s\n",
      "epoch 60, training loss: 1.637670, time: 0.1s\n",
      "epoch 70, training loss: 1.672982, time: 0.1s\n",
      "epoch 80, training loss: 1.810223, time: 0.1s\n",
      "epoch 90, training loss: 1.370650, time: 0.1s\n",
      "epoch100, training loss: 1.307680, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 59.320950, time: 0.1s\n",
      "epoch 10, training loss: 6.262051, time: 0.1s\n",
      "epoch 20, training loss: 4.020307, time: 0.1s\n",
      "epoch 30, training loss: 2.990011, time: 0.1s\n",
      "epoch 40, training loss: 2.463659, time: 0.1s\n",
      "epoch 50, training loss: 2.004102, time: 0.1s\n",
      "epoch 60, training loss: 1.853826, time: 0.1s\n",
      "epoch 70, training loss: 1.628603, time: 0.1s\n",
      "epoch 80, training loss: 1.396798, time: 0.1s\n",
      "epoch 90, training loss: 1.366729, time: 0.1s\n",
      "epoch100, training loss: 1.309458, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 11/11 [00:00<00:00, 379.59it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 397.16it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 410.16it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 391.41it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 395.87it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 406.41it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 405.49it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 246.03it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 386.74it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 407.21it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 356.39it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 394.17it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 371.68it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 257.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current noise type: None\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "kernel size: 16\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=150, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=16, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 6.384683, time: 0.4s\n",
      "epoch 10, training loss: 4.232786, time: 0.3s\n",
      "epoch 20, training loss: 3.617534, time: 0.3s\n",
      "epoch 30, training loss: 3.135981, time: 0.3s\n",
      "epoch 40, training loss: 2.726606, time: 0.3s\n",
      "epoch 50, training loss: 2.502278, time: 0.3s\n",
      "epoch 60, training loss: 2.307264, time: 0.3s\n",
      "epoch 70, training loss: 2.138920, time: 0.3s\n",
      "epoch 80, training loss: 1.996738, time: 0.3s\n",
      "epoch 90, training loss: 1.983824, time: 0.3s\n",
      "epoch100, training loss: 1.814121, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 34/34 [00:00<00:00, 293.51it/s]\n",
      "testing: 100%|██████████| 15/15 [00:00<00:00, 304.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current noise type: None\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 6\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1, training loss: 33.162752, time: 0.1s\n",
      "epoch 10, training loss: 1.450437, time: 0.1s\n",
      "epoch 20, training loss: 1.168082, time: 0.1s\n",
      "epoch 30, training loss: 1.022032, time: 0.1s\n",
      "epoch 40, training loss: 0.913861, time: 0.1s\n",
      "epoch 50, training loss: 0.858695, time: 0.1s\n",
      "epoch 60, training loss: 0.832699, time: 0.1s\n",
      "epoch 70, training loss: 0.792271, time: 0.1s\n",
      "epoch 80, training loss: 0.711186, time: 0.1s\n",
      "epoch 90, training loss: 0.691919, time: 0.1s\n",
      "epoch100, training loss: 0.697396, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 28.933198, time: 0.1s\n",
      "epoch 10, training loss: 1.540289, time: 0.1s\n",
      "epoch 20, training loss: 1.167575, time: 0.1s\n",
      "epoch 30, training loss: 0.918887, time: 0.1s\n",
      "epoch 40, training loss: 0.793687, time: 0.1s\n",
      "epoch 50, training loss: 0.712696, time: 0.1s\n",
      "epoch 60, training loss: 0.667666, time: 0.1s\n",
      "epoch 70, training loss: 0.652649, time: 0.1s\n",
      "epoch 80, training loss: 0.636960, time: 0.1s\n",
      "epoch 90, training loss: 0.568570, time: 0.1s\n",
      "epoch100, training loss: 0.537787, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 35.375245, time: 0.1s\n",
      "epoch 10, training loss: 1.873381, time: 0.1s\n",
      "epoch 20, training loss: 1.332442, time: 0.1s\n",
      "epoch 30, training loss: 1.231207, time: 0.1s\n",
      "epoch 40, training loss: 0.966030, time: 0.1s\n",
      "epoch 50, training loss: 0.918390, time: 0.1s\n",
      "epoch 60, training loss: 0.873981, time: 0.1s\n",
      "epoch 70, training loss: 0.790755, time: 0.1s\n",
      "epoch 80, training loss: 0.720251, time: 0.1s\n",
      "epoch 90, training loss: 0.715595, time: 0.1s\n",
      "epoch100, training loss: 0.657617, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 40.750863, time: 0.1s\n",
      "epoch 10, training loss: 2.611879, time: 0.1s\n",
      "epoch 20, training loss: 1.862924, time: 0.1s\n",
      "epoch 30, training loss: 1.156952, time: 0.1s\n",
      "epoch 40, training loss: 0.998700, time: 0.1s\n",
      "epoch 50, training loss: 0.905753, time: 0.1s\n",
      "epoch 60, training loss: 0.846197, time: 0.1s\n",
      "epoch 70, training loss: 0.810715, time: 0.1s\n",
      "epoch 80, training loss: 0.743264, time: 0.1s\n",
      "epoch 90, training loss: 0.686449, time: 0.1s\n",
      "epoch100, training loss: 0.713195, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 36.340785, time: 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 1.771345, time: 0.1s\n",
      "epoch 20, training loss: 1.277593, time: 0.1s\n",
      "epoch 30, training loss: 1.009374, time: 0.1s\n",
      "epoch 40, training loss: 0.939300, time: 0.1s\n",
      "epoch 50, training loss: 0.930740, time: 0.1s\n",
      "epoch 60, training loss: 0.801810, time: 0.1s\n",
      "epoch 70, training loss: 0.846673, time: 0.1s\n",
      "epoch 80, training loss: 0.733163, time: 0.1s\n",
      "epoch 90, training loss: 0.694137, time: 0.1s\n",
      "epoch100, training loss: 0.683217, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 28.128757, time: 0.1s\n",
      "epoch 10, training loss: 1.482297, time: 0.1s\n",
      "epoch 20, training loss: 1.089636, time: 0.1s\n",
      "epoch 30, training loss: 1.012150, time: 0.1s\n",
      "epoch 40, training loss: 0.944334, time: 0.1s\n",
      "epoch 50, training loss: 0.896048, time: 0.1s\n",
      "epoch 60, training loss: 0.846152, time: 0.1s\n",
      "epoch 70, training loss: 0.808572, time: 0.1s\n",
      "epoch 80, training loss: 0.787940, time: 0.1s\n",
      "epoch 90, training loss: 0.753720, time: 0.1s\n",
      "epoch100, training loss: 0.710180, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 16/16 [00:00<00:00, 405.22it/s]\n",
      "testing: 100%|██████████| 16/16 [00:00<00:00, 354.22it/s]\n",
      "testing: 100%|██████████| 16/16 [00:00<00:00, 383.62it/s]\n",
      "testing: 100%|██████████| 16/16 [00:00<00:00, 390.31it/s]\n",
      "testing: 100%|██████████| 16/16 [00:00<00:00, 364.83it/s]\n",
      "testing: 100%|██████████| 16/16 [00:00<00:00, 391.62it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 388.56it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 377.82it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 380.24it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 367.36it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 374.43it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 321.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current noise type: None\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 8\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 29.218465, time: 0.2s\n",
      "epoch 10, training loss: 0.901963, time: 0.2s\n",
      "epoch 20, training loss: 0.484374, time: 0.3s\n",
      "epoch 30, training loss: 0.369372, time: 0.3s\n",
      "epoch 40, training loss: 0.388006, time: 0.2s\n",
      "epoch 50, training loss: 0.305867, time: 0.2s\n",
      "epoch 60, training loss: 0.263801, time: 0.2s\n",
      "epoch 70, training loss: 0.268020, time: 0.3s\n",
      "epoch 80, training loss: 0.270495, time: 0.2s\n",
      "epoch 90, training loss: 0.236442, time: 0.2s\n",
      "epoch100, training loss: 0.326870, time: 0.2s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 19.193649, time: 0.3s\n",
      "epoch 10, training loss: 0.702553, time: 0.2s\n",
      "epoch 20, training loss: 0.393976, time: 0.2s\n",
      "epoch 30, training loss: 0.304987, time: 0.2s\n",
      "epoch 40, training loss: 0.349018, time: 0.3s\n",
      "epoch 50, training loss: 0.357506, time: 0.3s\n",
      "epoch 60, training loss: 0.279786, time: 0.2s\n",
      "epoch 70, training loss: 0.222097, time: 0.3s\n",
      "epoch 80, training loss: 0.242448, time: 0.3s\n",
      "epoch 90, training loss: 0.236310, time: 0.2s\n",
      "epoch100, training loss: 0.205595, time: 0.2s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 25.089683, time: 0.2s\n",
      "epoch 10, training loss: 0.900525, time: 0.3s\n",
      "epoch 20, training loss: 0.473303, time: 0.2s\n",
      "epoch 30, training loss: 0.405150, time: 0.3s\n",
      "epoch 40, training loss: 0.351408, time: 0.2s\n",
      "epoch 50, training loss: 0.357196, time: 0.2s\n",
      "epoch 60, training loss: 0.310211, time: 0.2s\n",
      "epoch 70, training loss: 0.277882, time: 0.2s\n",
      "epoch 80, training loss: 0.249741, time: 0.3s\n",
      "epoch 90, training loss: 0.221648, time: 0.3s\n",
      "epoch100, training loss: 0.229024, time: 0.2s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1, training loss: 36.904547, time: 0.3s\n",
      "epoch 10, training loss: 1.104519, time: 0.2s\n",
      "epoch 20, training loss: 0.607233, time: 0.2s\n",
      "epoch 30, training loss: 0.453211, time: 0.2s\n",
      "epoch 40, training loss: 0.424869, time: 0.3s\n",
      "epoch 50, training loss: 0.385977, time: 0.2s\n",
      "epoch 60, training loss: 0.357614, time: 0.2s\n",
      "epoch 70, training loss: 0.294661, time: 0.2s\n",
      "epoch 80, training loss: 0.334352, time: 0.2s\n",
      "epoch 90, training loss: 0.266011, time: 0.2s\n",
      "epoch100, training loss: 0.230215, time: 0.3s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 19.757168, time: 0.3s\n",
      "epoch 10, training loss: 0.770969, time: 0.3s\n",
      "epoch 20, training loss: 0.470639, time: 0.2s\n",
      "epoch 30, training loss: 0.346924, time: 0.3s\n",
      "epoch 40, training loss: 0.304493, time: 0.3s\n",
      "epoch 50, training loss: 0.312785, time: 0.3s\n",
      "epoch 60, training loss: 0.284431, time: 0.2s\n",
      "epoch 70, training loss: 0.242187, time: 0.3s\n",
      "epoch 80, training loss: 0.248984, time: 0.2s\n",
      "epoch 90, training loss: 0.239625, time: 0.2s\n",
      "epoch100, training loss: 0.219735, time: 0.3s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 17.717221, time: 0.3s\n",
      "epoch 10, training loss: 0.948056, time: 0.2s\n",
      "epoch 20, training loss: 0.498522, time: 0.2s\n",
      "epoch 30, training loss: 0.601816, time: 0.3s\n",
      "epoch 40, training loss: 0.351720, time: 0.3s\n",
      "epoch 50, training loss: 0.283096, time: 0.3s\n",
      "epoch 60, training loss: 0.268995, time: 0.2s\n",
      "epoch 70, training loss: 0.263044, time: 0.3s\n",
      "epoch 80, training loss: 0.363474, time: 0.2s\n",
      "epoch 90, training loss: 0.270429, time: 0.2s\n",
      "epoch100, training loss: 0.245085, time: 0.2s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 16.892330, time: 0.3s\n",
      "epoch 10, training loss: 0.936685, time: 0.2s\n",
      "epoch 20, training loss: 0.465903, time: 0.3s\n",
      "epoch 30, training loss: 0.406803, time: 0.3s\n",
      "epoch 40, training loss: 0.326253, time: 0.2s\n",
      "epoch 50, training loss: 0.315352, time: 0.2s\n",
      "epoch 60, training loss: 0.336152, time: 0.3s\n",
      "epoch 70, training loss: 0.268782, time: 0.2s\n",
      "epoch 80, training loss: 0.223738, time: 0.3s\n",
      "epoch 90, training loss: 0.238991, time: 0.2s\n",
      "epoch100, training loss: 0.226280, time: 0.3s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1, training loss: 21.067305, time: 0.2s\n",
      "epoch 10, training loss: 0.737990, time: 0.2s\n",
      "epoch 20, training loss: 0.385057, time: 0.2s\n",
      "epoch 30, training loss: 0.329420, time: 0.2s\n",
      "epoch 40, training loss: 0.295736, time: 0.2s\n",
      "epoch 50, training loss: 0.328127, time: 0.2s\n",
      "epoch 60, training loss: 0.231093, time: 0.2s\n",
      "epoch 70, training loss: 0.239335, time: 0.2s\n",
      "epoch 80, training loss: 0.238083, time: 0.2s\n",
      "epoch 90, training loss: 0.222905, time: 0.2s\n",
      "epoch100, training loss: 0.205138, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 42/42 [00:00<00:00, 468.70it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 463.48it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 475.17it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 433.58it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 460.87it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 466.67it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 426.78it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 441.52it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 452.84it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 444.04it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 460.25it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 457.02it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 398.96it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 424.02it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 425.99it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 411.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# seed for reproducible results\n",
    "seed = 42\n",
    "\n",
    "for dataset in dataset_list:\n",
    "    # import the dataset\n",
    "    datagenerator.dataset = dataset  # specify the dataset name\n",
    "    data = datagenerator.generator(\n",
    "        la=0.1, realistic_synthetic_mode=None, noise_type=None\n",
    "    )  # only 10% labeled anomalies are available\n",
    "\n",
    "    for name, clf in model_dict.items():\n",
    "        # model initialization\n",
    "        clf = clf(seed=seed, model_name=name)\n",
    "\n",
    "        # training, for unsupervised models the y label will be discarded\n",
    "        clf = clf.fit(X_train=data[\"X_train\"], y_train=data[\"y_train\"])\n",
    "\n",
    "        # output predicted anomaly score on testing set\n",
    "        score = clf.predict_score(data[\"X_test\"])\n",
    "\n",
    "        # evaluation\n",
    "        result = utils.metric(y_true=data[\"y_test\"], y_score=score)\n",
    "\n",
    "        # save results\n",
    "        df_AUCROC.loc[dataset, name] = result[\"aucroc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-brain",
   "metadata": {},
   "source": [
    "## Metrics and Results \n",
    "The Area Under the Receiver Operating Characteristic (AUROC) curve is a fundamental metric used to evaluate the performance of anomaly detection models. It provides insight into how well a model can distinguish between normal and anomalous instances across various threshold settings. AUC represents the degree or measure of separability calculated using ROC curves. It indicates how well the model can distinguish between classes. The higher the AUC, the better the model predicts 0 classes as 0 and 1 classes as 1. Below is a table that shows AUCROC values for different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cognitive-shape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6_cardio</th>\n",
       "      <td>0.793364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_fraud</th>\n",
       "      <td>0.867379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24_mnist</th>\n",
       "      <td>0.892911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42_WBC</th>\n",
       "      <td>0.952828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43_WDBC</th>\n",
       "      <td>0.974138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_breastw</th>\n",
       "      <td>0.826051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25_musk</th>\n",
       "      <td>0.999109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40_vowels</th>\n",
       "      <td>0.850237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38_thyroid</th>\n",
       "      <td>0.864163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ICL\n",
       "6_cardio    0.793364\n",
       "13_fraud    0.867379\n",
       "24_mnist    0.892911\n",
       "42_WBC      0.952828\n",
       "43_WDBC     0.974138\n",
       "4_breastw   0.826051\n",
       "25_musk     0.999109\n",
       "40_vowels   0.850237\n",
       "38_thyroid  0.864163"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AUCROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-premium",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
