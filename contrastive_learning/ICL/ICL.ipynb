{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expanded-battle",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we will delve into the comprehensive exploration of the paper titled [\"Anomaly Detection for Tabular Data with Internal Contrastive Learning.\"](https://openreview.net/forum?id=_hszZbt46bT) This paper introduces an innovative approach to anomaly detection by addressing the challenge of identifying out-of-class samples within tabular data, particularly when the data's structural characteristics are not well understood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-brooks",
   "metadata": {},
   "source": [
    "## Masking in ICL\n",
    "\n",
    "The image below illustrates how ICL masks a feature vector for contrastive learning. The underlying learning problem. Given a **sample vector** $x_i$, they consider the **subvector** $a_i^3$ and its **complementary** $b_i^3$. The networks are trained to produce similar embeddings for this pair of vectors, while distancing the embedding of $a_i^{j^{\\prime}}$ for $j^{\\prime} \\neq 3$ from that of $b_i^3$.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1WOfi9boxWG4ET3AKochRS8OaGtDjxmZe\" width=\"500\" aligh=\"center\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dd5c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):  # type: ignore # noqa: F821\n",
    "    %pip install copulas deepod pyod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mysterious-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from data_generator import DataGenerator\n",
    "from myutils import Utils\n",
    "from pyod_base import PYOD\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action=\"once\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-navigator",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "In this part, we will work with the [\"Outlier Detection DataSets (ODDS)\"](https://odds.cs.stonybrook.edu/) dataset, a widely-used benchmark collection of datasets specifically designed for evaluating outlier detection algorithms. The ODDS dataset encompasses a diverse range of data types, structures, and characteristics, making it an ideal choice for assessing the effectiveness of anomaly detection methodologies. In the next cell we see all the datasets are reachable via ODDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "capital-holocaust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18_Ionosphere.npz',\n",
       " '3_backdoor.npz',\n",
       " '42_WBC.npz',\n",
       " '35_SpamBase.npz',\n",
       " '47_yeast.npz',\n",
       " '26_optdigits.npz',\n",
       " '24_mnist.npz',\n",
       " '33_skin.npz',\n",
       " '16_http.npz',\n",
       " '43_WDBC.npz',\n",
       " '22_magic.gamma.npz',\n",
       " '28_pendigits.npz',\n",
       " '1_ALOI.npz',\n",
       " '5_campaign.npz',\n",
       " '32_shuttle.npz',\n",
       " '2_annthyroid.npz',\n",
       " '6_cardio.npz',\n",
       " '34_smtp.npz',\n",
       " '45_wine.npz',\n",
       " '12_fault.npz',\n",
       " '13_fraud.npz',\n",
       " '29_Pima.npz',\n",
       " '10_cover.npz',\n",
       " '9_census.npz',\n",
       " '36_speech.npz',\n",
       " '39_vertebral.npz',\n",
       " '15_Hepatitis.npz',\n",
       " '7_Cardiotocography.npz',\n",
       " '40_vowels.npz',\n",
       " '25_musk.npz',\n",
       " '41_Waveform.npz',\n",
       " '44_Wilt.npz',\n",
       " '46_WPBC.npz',\n",
       " '11_donors.npz',\n",
       " '21_Lymphography.npz',\n",
       " '17_InternetAds.npz',\n",
       " '31_satimage-2.npz',\n",
       " '8_celeba.npz',\n",
       " '27_PageBlocks.npz',\n",
       " '38_thyroid.npz',\n",
       " '30_satellite.npz',\n",
       " '4_breastw.npz',\n",
       " '37_Stamps.npz',\n",
       " '19_landsat.npz',\n",
       " '23_mammography.npz',\n",
       " '20_letter.npz',\n",
       " '14_glass.npz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagenerator = DataGenerator()  # data generator\n",
    "utils = Utils()  # utils function\n",
    "os.listdir(\"datasets/Classical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baking-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = [\n",
    "    \"6_cardio\",\n",
    "    \"13_fraud\",\n",
    "    \"24_mnist\",\n",
    "    \"42_WBC\",\n",
    "    \"43_WDBC\",\n",
    "    \"4_breastw\",\n",
    "    \"25_musk\",\n",
    "    \"40_vowels\",\n",
    "    \"38_thyroid\",\n",
    "]  # choosing the datasets\n",
    "model_dict = {\"ICL\": PYOD}  # choosing the model\n",
    "\n",
    "# save the results\n",
    "df_AUCROC = pd.DataFrame(data=None, index=dataset_list, columns=model_dict.keys())\n",
    "df_AUCPR = pd.DataFrame(data=None, index=dataset_list, columns=model_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greatest-steps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current noise type: None\n",
      "{'Samples': 1831, 'Features': 21, 'Anomalies': 176, 'Anomalies Ratio(%)': 9.61}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 4\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=19, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 23.454693, time: 1.1s\n",
      "epoch 10, training loss: 2.410294, time: 0.1s\n",
      "epoch 20, training loss: 1.926891, time: 0.2s\n",
      "epoch 30, training loss: 2.073260, time: 0.2s\n",
      "epoch 40, training loss: 1.346864, time: 0.2s\n",
      "epoch 50, training loss: 1.456022, time: 0.2s\n",
      "epoch 60, training loss: 0.999825, time: 0.2s\n",
      "epoch 70, training loss: 1.133194, time: 0.1s\n",
      "epoch 80, training loss: 1.450800, time: 0.2s\n",
      "epoch 90, training loss: 1.119740, time: 0.2s\n",
      "epoch100, training loss: 1.123200, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=19, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 23.668192, time: 0.1s\n",
      "epoch 10, training loss: 2.618490, time: 0.1s\n",
      "epoch 20, training loss: 1.803053, time: 0.2s\n",
      "epoch 30, training loss: 1.450072, time: 0.2s\n",
      "epoch 40, training loss: 1.386179, time: 0.2s\n",
      "epoch 50, training loss: 1.141813, time: 0.2s\n",
      "epoch 60, training loss: 1.362055, time: 0.2s\n",
      "epoch 70, training loss: 1.165161, time: 0.2s\n",
      "epoch 80, training loss: 1.570335, time: 0.1s\n",
      "epoch 90, training loss: 1.130047, time: 0.2s\n",
      "epoch100, training loss: 1.282426, time: 0.2s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=19, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 24.370722, time: 0.2s\n",
      "epoch 10, training loss: 2.715386, time: 0.2s\n",
      "epoch 20, training loss: 1.708555, time: 0.2s\n",
      "epoch 30, training loss: 1.403677, time: 0.2s\n",
      "epoch 40, training loss: 1.281717, time: 0.2s\n",
      "epoch 50, training loss: 1.189191, time: 0.2s\n",
      "epoch 60, training loss: 1.089853, time: 0.2s\n",
      "epoch 70, training loss: 1.223911, time: 0.2s\n",
      "epoch 80, training loss: 1.047861, time: 0.2s\n",
      "epoch 90, training loss: 1.054045, time: 0.2s\n",
      "epoch100, training loss: 1.026316, time: 0.2s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=19, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 22.401813, time: 0.2s\n",
      "epoch 10, training loss: 2.456641, time: 0.1s\n",
      "epoch 20, training loss: 1.718342, time: 0.1s\n",
      "epoch 30, training loss: 1.969649, time: 0.1s\n",
      "epoch 40, training loss: 1.387178, time: 0.2s\n",
      "epoch 50, training loss: 1.321773, time: 0.2s\n",
      "epoch 60, training loss: 1.184589, time: 0.2s\n",
      "epoch 70, training loss: 1.262119, time: 0.2s\n",
      "epoch 80, training loss: 1.176873, time: 0.2s\n",
      "epoch 90, training loss: 1.132189, time: 0.2s\n",
      "epoch100, training loss: 1.130423, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 21/21 [00:00<00:00, 324.18it/s]\n",
      "testing: 100%|██████████| 21/21 [00:00<00:00, 325.28it/s]\n",
      "testing: 100%|██████████| 21/21 [00:00<00:00, 322.60it/s]\n",
      "testing: 100%|██████████| 21/21 [00:00<00:00, 329.54it/s]\n",
      "testing: 100%|██████████| 9/9 [00:00<00:00, 304.91it/s]\n",
      "testing: 100%|██████████| 9/9 [00:00<00:00, 295.74it/s]\n",
      "testing: 100%|██████████| 9/9 [00:00<00:00, 304.86it/s]\n",
      "testing: 100%|██████████| 9/9 [00:00<00:00, 292.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsampling for dataset 13_fraud...\n",
      "current noise type: None\n",
      "{'Samples': 10000, 'Features': 29, 'Anomalies': 16, 'Anomalies Ratio(%)': 0.16}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=27, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 4.148517, time: 1.0s\n",
      "epoch 10, training loss: 2.093605, time: 1.0s\n",
      "epoch 20, training loss: 1.755030, time: 0.9s\n",
      "epoch 30, training loss: 1.487752, time: 1.0s\n",
      "epoch 40, training loss: 1.292715, time: 0.9s\n",
      "epoch 50, training loss: 1.053313, time: 0.8s\n",
      "epoch 60, training loss: 0.966508, time: 0.9s\n",
      "epoch 70, training loss: 0.856006, time: 0.8s\n",
      "epoch 80, training loss: 0.936474, time: 0.9s\n",
      "epoch 90, training loss: 0.745442, time: 0.9s\n",
      "epoch100, training loss: 0.750319, time: 0.9s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=27, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 5.554015, time: 0.9s\n",
      "epoch 10, training loss: 1.810795, time: 0.9s\n",
      "epoch 20, training loss: 1.425073, time: 0.9s\n",
      "epoch 30, training loss: 1.134234, time: 1.0s\n",
      "epoch 40, training loss: 0.945306, time: 1.0s\n",
      "epoch 50, training loss: 0.799565, time: 1.0s\n",
      "epoch 60, training loss: 0.755849, time: 0.9s\n",
      "epoch 70, training loss: 0.653477, time: 1.0s\n",
      "epoch 80, training loss: 0.669582, time: 0.9s\n",
      "epoch 90, training loss: 0.567222, time: 0.9s\n",
      "epoch100, training loss: 0.523404, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=27, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 4.439934, time: 1.0s\n",
      "epoch 10, training loss: 1.751113, time: 1.0s\n",
      "epoch 20, training loss: 1.329372, time: 0.9s\n",
      "epoch 30, training loss: 1.202112, time: 0.8s\n",
      "epoch 40, training loss: 1.530806, time: 0.8s\n",
      "epoch 50, training loss: 0.846095, time: 1.0s\n",
      "epoch 60, training loss: 0.757834, time: 1.0s\n",
      "epoch 70, training loss: 0.681858, time: 0.8s\n",
      "epoch 80, training loss: 0.642864, time: 1.0s\n",
      "epoch 90, training loss: 0.628892, time: 0.9s\n",
      "epoch100, training loss: 0.571980, time: 1.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 110/110 [00:00<00:00, 292.04it/s]\n",
      "testing: 100%|██████████| 110/110 [00:00<00:00, 366.54it/s]\n",
      "testing: 100%|██████████| 110/110 [00:00<00:00, 354.20it/s]\n",
      "testing: 100%|██████████| 47/47 [00:00<00:00, 289.51it/s]\n",
      "testing: 100%|██████████| 47/47 [00:00<00:00, 266.77it/s]\n",
      "testing: 100%|██████████| 47/47 [00:00<00:00, 337.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current noise type: None\n",
      "{'Samples': 7603, 'Features': 100, 'Anomalies': 700, 'Anomalies Ratio(%)': 9.21}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=90, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(91, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 7.235301, time: 0.8s\n",
      "epoch 10, training loss: 2.697678, time: 0.7s\n",
      "epoch 20, training loss: 2.173014, time: 0.8s\n",
      "epoch 30, training loss: 1.838425, time: 0.8s\n",
      "epoch 40, training loss: 1.809295, time: 0.8s\n",
      "epoch 50, training loss: 1.564143, time: 0.8s\n",
      "epoch 60, training loss: 1.489870, time: 0.7s\n",
      "epoch 70, training loss: 1.436201, time: 0.8s\n",
      "epoch 80, training loss: 1.401334, time: 0.7s\n",
      "epoch 90, training loss: 1.435534, time: 0.7s\n",
      "epoch100, training loss: 1.377018, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 84/84 [00:00<00:00, 293.74it/s]\n",
      "testing: 100%|██████████| 36/36 [00:00<00:00, 290.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 42_WBC...\n",
      "current noise type: None\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 44, 'Anomalies Ratio(%)': 4.4}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 7\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 81.311814, time: 0.1s\n",
      "epoch 10, training loss: 5.868455, time: 0.1s\n",
      "epoch 20, training loss: 4.123191, time: 0.1s\n",
      "epoch 30, training loss: 3.336899, time: 0.1s\n",
      "epoch 40, training loss: 2.120764, time: 0.1s\n",
      "epoch 50, training loss: 2.268210, time: 0.1s\n",
      "epoch 60, training loss: 1.714451, time: 0.1s\n",
      "epoch 70, training loss: 1.707119, time: 0.1s\n",
      "epoch 80, training loss: 1.526228, time: 0.1s\n",
      "epoch 90, training loss: 1.148954, time: 0.1s\n",
      "epoch100, training loss: 1.380639, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 90.114490, time: 0.1s\n",
      "epoch 10, training loss: 8.879294, time: 0.1s\n",
      "epoch 20, training loss: 4.992617, time: 0.1s\n",
      "epoch 30, training loss: 4.167034, time: 0.1s\n",
      "epoch 40, training loss: 3.561490, time: 0.1s\n",
      "epoch 50, training loss: 3.234136, time: 0.1s\n",
      "epoch 60, training loss: 2.999345, time: 0.1s\n",
      "epoch 70, training loss: 2.619627, time: 0.1s\n",
      "epoch 80, training loss: 2.204422, time: 0.1s\n",
      "epoch 90, training loss: 2.158410, time: 0.1s\n",
      "epoch100, training loss: 1.963137, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 88.683981, time: 0.1s\n",
      "epoch 10, training loss: 8.600296, time: 0.1s\n",
      "epoch 20, training loss: 4.665760, time: 0.1s\n",
      "epoch 30, training loss: 4.449682, time: 0.1s\n",
      "epoch 40, training loss: 3.301830, time: 0.1s\n",
      "epoch 50, training loss: 2.686963, time: 0.1s\n",
      "epoch 60, training loss: 2.537857, time: 0.1s\n",
      "epoch 70, training loss: 2.345593, time: 0.1s\n",
      "epoch 80, training loss: 2.126734, time: 0.1s\n",
      "epoch 90, training loss: 1.602416, time: 0.1s\n",
      "epoch100, training loss: 1.498221, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 82.276891, time: 0.1s\n",
      "epoch 10, training loss: 7.460176, time: 0.1s\n",
      "epoch 20, training loss: 4.514318, time: 0.1s\n",
      "epoch 30, training loss: 3.253325, time: 0.1s\n",
      "epoch 40, training loss: 2.597877, time: 0.1s\n",
      "epoch 50, training loss: 2.775661, time: 0.1s\n",
      "epoch 60, training loss: 2.399912, time: 0.1s\n",
      "epoch 70, training loss: 2.188711, time: 0.1s\n",
      "epoch 80, training loss: 2.147900, time: 0.1s\n",
      "epoch 90, training loss: 1.657577, time: 0.1s\n",
      "epoch100, training loss: 1.558133, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 74.382614, time: 0.1s\n",
      "epoch 10, training loss: 7.266660, time: 0.1s\n",
      "epoch 20, training loss: 4.702162, time: 0.1s\n",
      "epoch 30, training loss: 3.426771, time: 0.1s\n",
      "epoch 40, training loss: 2.973962, time: 0.1s\n",
      "epoch 50, training loss: 2.508278, time: 0.1s\n",
      "epoch 60, training loss: 2.291205, time: 0.1s\n",
      "epoch 70, training loss: 1.822697, time: 0.1s\n",
      "epoch 80, training loss: 2.096061, time: 0.1s\n",
      "epoch 90, training loss: 1.803747, time: 0.1s\n",
      "epoch100, training loss: 1.572442, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 79.767037, time: 0.1s\n",
      "epoch 10, training loss: 7.490853, time: 0.1s\n",
      "epoch 20, training loss: 5.126416, time: 0.1s\n",
      "epoch 30, training loss: 3.717030, time: 0.1s\n",
      "epoch 40, training loss: 2.779491, time: 0.1s\n",
      "epoch 50, training loss: 2.408553, time: 0.1s\n",
      "epoch 60, training loss: 3.025280, time: 0.1s\n",
      "epoch 70, training loss: 2.048965, time: 0.1s\n",
      "epoch 80, training loss: 2.042275, time: 0.1s\n",
      "epoch 90, training loss: 1.698562, time: 0.1s\n",
      "epoch100, training loss: 1.505450, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 71.979256, time: 0.1s\n",
      "epoch 10, training loss: 7.881646, time: 0.1s\n",
      "epoch 20, training loss: 4.491093, time: 0.1s\n",
      "epoch 30, training loss: 4.482272, time: 0.1s\n",
      "epoch 40, training loss: 3.550430, time: 0.1s\n",
      "epoch 50, training loss: 2.983251, time: 0.1s\n",
      "epoch 60, training loss: 2.719299, time: 0.1s\n",
      "epoch 70, training loss: 2.189467, time: 0.1s\n",
      "epoch 80, training loss: 2.104519, time: 0.1s\n",
      "epoch 90, training loss: 1.685877, time: 0.1s\n",
      "epoch100, training loss: 1.951537, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 11/11 [00:00<00:00, 411.18it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 416.57it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 269.48it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 306.65it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 329.99it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 335.53it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 309.22it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 323.61it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 303.07it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 293.98it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 322.08it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 285.07it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 290.35it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 303.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 43_WDBC...\n",
      "current noise type: None\n",
      "{'Samples': 1000, 'Features': 30, 'Anomalies': 33, 'Anomalies Ratio(%)': 3.3}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=28, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 20.361143, time: 0.1s\n",
      "epoch 10, training loss: 3.233239, time: 0.1s\n",
      "epoch 20, training loss: 2.764909, time: 0.1s\n",
      "epoch 30, training loss: 2.518829, time: 0.1s\n",
      "epoch 40, training loss: 2.390741, time: 0.1s\n",
      "epoch 50, training loss: 2.285093, time: 0.1s\n",
      "epoch 60, training loss: 2.185232, time: 0.1s\n",
      "epoch 70, training loss: 2.116009, time: 0.1s\n",
      "epoch 80, training loss: 2.024424, time: 0.1s\n",
      "epoch 90, training loss: 2.094420, time: 0.1s\n",
      "epoch100, training loss: 2.003311, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=28, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 23.768149, time: 0.1s\n",
      "epoch 10, training loss: 3.544331, time: 0.1s\n",
      "epoch 20, training loss: 2.908149, time: 0.1s\n",
      "epoch 30, training loss: 2.681915, time: 0.1s\n",
      "epoch 40, training loss: 2.585751, time: 0.1s\n",
      "epoch 50, training loss: 2.449894, time: 0.1s\n",
      "epoch 60, training loss: 2.412443, time: 0.1s\n",
      "epoch 70, training loss: 2.361201, time: 0.1s\n",
      "epoch 80, training loss: 2.230608, time: 0.1s\n",
      "epoch 90, training loss: 2.193296, time: 0.1s\n",
      "epoch100, training loss: 2.114835, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=28, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 24.010203, time: 0.1s\n",
      "epoch 10, training loss: 3.254895, time: 0.1s\n",
      "epoch 20, training loss: 2.819153, time: 0.1s\n",
      "epoch 30, training loss: 2.570817, time: 0.1s\n",
      "epoch 40, training loss: 2.484141, time: 0.1s\n",
      "epoch 50, training loss: 2.341665, time: 0.1s\n",
      "epoch 60, training loss: 2.270003, time: 0.1s\n",
      "epoch 70, training loss: 2.222890, time: 0.1s\n",
      "epoch 80, training loss: 2.127624, time: 0.1s\n",
      "epoch 90, training loss: 2.087237, time: 0.1s\n",
      "epoch100, training loss: 2.006832, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 11/11 [00:00<00:00, 290.36it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 353.60it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 354.30it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 365.45it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 363.77it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 374.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating duplicate samples for dataset 4_breastw...\n",
      "current noise type: None\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 360, 'Anomalies Ratio(%)': 36.0}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 7\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1, training loss: 67.960077, time: 0.1s\n",
      "epoch 10, training loss: 5.922819, time: 0.1s\n",
      "epoch 20, training loss: 4.512699, time: 0.1s\n",
      "epoch 30, training loss: 2.826114, time: 0.1s\n",
      "epoch 40, training loss: 2.110901, time: 0.1s\n",
      "epoch 50, training loss: 1.642379, time: 0.1s\n",
      "epoch 60, training loss: 1.608773, time: 0.1s\n",
      "epoch 70, training loss: 1.415740, time: 0.1s\n",
      "epoch 80, training loss: 1.408265, time: 0.1s\n",
      "epoch 90, training loss: 1.284295, time: 0.1s\n",
      "epoch100, training loss: 1.084434, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 71.475225, time: 0.1s\n",
      "epoch 10, training loss: 8.259924, time: 0.1s\n",
      "epoch 20, training loss: 4.709119, time: 0.1s\n",
      "epoch 30, training loss: 3.464675, time: 0.1s\n",
      "epoch 40, training loss: 3.219796, time: 0.1s\n",
      "epoch 50, training loss: 2.817601, time: 0.1s\n",
      "epoch 60, training loss: 1.846856, time: 0.1s\n",
      "epoch 70, training loss: 1.982103, time: 0.1s\n",
      "epoch 80, training loss: 1.743389, time: 0.1s\n",
      "epoch 90, training loss: 1.800021, time: 0.1s\n",
      "epoch100, training loss: 1.429291, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 69.222927, time: 0.1s\n",
      "epoch 10, training loss: 7.431498, time: 0.1s\n",
      "epoch 20, training loss: 4.150641, time: 0.1s\n",
      "epoch 30, training loss: 3.139024, time: 0.1s\n",
      "epoch 40, training loss: 2.671262, time: 0.1s\n",
      "epoch 50, training loss: 2.416335, time: 0.1s\n",
      "epoch 60, training loss: 1.908183, time: 0.1s\n",
      "epoch 70, training loss: 1.845262, time: 0.1s\n",
      "epoch 80, training loss: 1.692602, time: 0.1s\n",
      "epoch 90, training loss: 1.561762, time: 0.1s\n",
      "epoch100, training loss: 1.598464, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 62.927478, time: 0.1s\n",
      "epoch 10, training loss: 6.420014, time: 0.1s\n",
      "epoch 20, training loss: 3.408841, time: 0.1s\n",
      "epoch 30, training loss: 2.755921, time: 0.1s\n",
      "epoch 40, training loss: 2.065221, time: 0.1s\n",
      "epoch 50, training loss: 2.042411, time: 0.1s\n",
      "epoch 60, training loss: 1.887201, time: 0.1s\n",
      "epoch 70, training loss: 1.399920, time: 0.1s\n",
      "epoch 80, training loss: 1.400338, time: 0.1s\n",
      "epoch 90, training loss: 1.298294, time: 0.1s\n",
      "epoch100, training loss: 1.135850, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 62.099451, time: 0.1s\n",
      "epoch 10, training loss: 7.010805, time: 0.1s\n",
      "epoch 20, training loss: 4.063835, time: 0.1s\n",
      "epoch 30, training loss: 3.150791, time: 0.1s\n",
      "epoch 40, training loss: 2.122366, time: 0.1s\n",
      "epoch 50, training loss: 2.116168, time: 0.1s\n",
      "epoch 60, training loss: 1.786091, time: 0.1s\n",
      "epoch 70, training loss: 1.661699, time: 0.1s\n",
      "epoch 80, training loss: 1.374450, time: 0.1s\n",
      "epoch 90, training loss: 1.266468, time: 0.1s\n",
      "epoch100, training loss: 1.407918, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 67.376122, time: 0.1s\n",
      "epoch 10, training loss: 6.547023, time: 0.1s\n",
      "epoch 20, training loss: 3.504931, time: 0.1s\n",
      "epoch 30, training loss: 2.585037, time: 0.1s\n",
      "epoch 40, training loss: 2.321987, time: 0.1s\n",
      "epoch 50, training loss: 1.773794, time: 0.1s\n",
      "epoch 60, training loss: 1.637671, time: 0.1s\n",
      "epoch 70, training loss: 1.672982, time: 0.1s\n",
      "epoch 80, training loss: 1.810223, time: 0.1s\n",
      "epoch 90, training loss: 1.370650, time: 0.1s\n",
      "epoch100, training loss: 1.307680, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=7, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 59.320947, time: 0.1s\n",
      "epoch 10, training loss: 6.262051, time: 0.1s\n",
      "epoch 20, training loss: 4.020307, time: 0.1s\n",
      "epoch 30, training loss: 2.990011, time: 0.1s\n",
      "epoch 40, training loss: 2.463659, time: 0.1s\n",
      "epoch 50, training loss: 2.004102, time: 0.1s\n",
      "epoch 60, training loss: 1.853826, time: 0.1s\n",
      "epoch 70, training loss: 1.628603, time: 0.1s\n",
      "epoch 80, training loss: 1.396798, time: 0.1s\n",
      "epoch 90, training loss: 1.366729, time: 0.1s\n",
      "epoch100, training loss: 1.309458, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 11/11 [00:00<00:00, 342.17it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 354.77it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 335.98it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 343.81it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 335.75it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 314.88it/s]\n",
      "testing: 100%|██████████| 11/11 [00:00<00:00, 334.41it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 344.38it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 327.04it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 345.24it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 337.78it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 344.50it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 332.78it/s]\n",
      "testing: 100%|██████████| 5/5 [00:00<00:00, 330.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current noise type: None\n",
      "{'Samples': 3062, 'Features': 166, 'Anomalies': 97, 'Anomalies Ratio(%)': 3.17}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "kernel size: 16\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=150, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=16, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(151, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 6.384683, time: 0.4s\n",
      "epoch 10, training loss: 4.232786, time: 0.3s\n",
      "epoch 20, training loss: 3.617534, time: 0.3s\n",
      "epoch 30, training loss: 3.135981, time: 0.3s\n",
      "epoch 40, training loss: 2.726606, time: 0.3s\n",
      "epoch 50, training loss: 2.502278, time: 0.3s\n",
      "epoch 60, training loss: 2.307264, time: 0.3s\n",
      "epoch 70, training loss: 2.138920, time: 0.3s\n",
      "epoch 80, training loss: 1.996738, time: 0.3s\n",
      "epoch 90, training loss: 1.983824, time: 0.3s\n",
      "epoch100, training loss: 1.814121, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 34/34 [00:00<00:00, 313.87it/s]\n",
      "testing: 100%|██████████| 15/15 [00:00<00:00, 281.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current noise type: None\n",
      "{'Samples': 1456, 'Features': 12, 'Anomalies': 50, 'Anomalies Ratio(%)': 3.43}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 6\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1, training loss: 33.162753, time: 0.1s\n",
      "epoch 10, training loss: 1.450437, time: 0.1s\n",
      "epoch 20, training loss: 1.168082, time: 0.1s\n",
      "epoch 30, training loss: 1.022032, time: 0.1s\n",
      "epoch 40, training loss: 0.913861, time: 0.1s\n",
      "epoch 50, training loss: 0.858695, time: 0.1s\n",
      "epoch 60, training loss: 0.832699, time: 0.1s\n",
      "epoch 70, training loss: 0.792271, time: 0.1s\n",
      "epoch 80, training loss: 0.711186, time: 0.1s\n",
      "epoch 90, training loss: 0.691919, time: 0.1s\n",
      "epoch100, training loss: 0.697396, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 28.933198, time: 0.1s\n",
      "epoch 10, training loss: 1.540289, time: 0.1s\n",
      "epoch 20, training loss: 1.167575, time: 0.1s\n",
      "epoch 30, training loss: 0.918887, time: 0.1s\n",
      "epoch 40, training loss: 0.793687, time: 0.1s\n",
      "epoch 50, training loss: 0.712696, time: 0.1s\n",
      "epoch 60, training loss: 0.667666, time: 0.1s\n",
      "epoch 70, training loss: 0.652649, time: 0.1s\n",
      "epoch 80, training loss: 0.636960, time: 0.1s\n",
      "epoch 90, training loss: 0.568570, time: 0.1s\n",
      "epoch100, training loss: 0.537787, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 35.375245, time: 0.1s\n",
      "epoch 10, training loss: 1.873381, time: 0.1s\n",
      "epoch 20, training loss: 1.332442, time: 0.1s\n",
      "epoch 30, training loss: 1.231207, time: 0.1s\n",
      "epoch 40, training loss: 0.966030, time: 0.1s\n",
      "epoch 50, training loss: 0.918390, time: 0.1s\n",
      "epoch 60, training loss: 0.873982, time: 0.1s\n",
      "epoch 70, training loss: 0.790755, time: 0.1s\n",
      "epoch 80, training loss: 0.720251, time: 0.1s\n",
      "epoch 90, training loss: 0.715595, time: 0.1s\n",
      "epoch100, training loss: 0.657617, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 40.750862, time: 0.1s\n",
      "epoch 10, training loss: 2.611879, time: 0.1s\n",
      "epoch 20, training loss: 1.862924, time: 0.1s\n",
      "epoch 30, training loss: 1.156952, time: 0.1s\n",
      "epoch 40, training loss: 0.998700, time: 0.1s\n",
      "epoch 50, training loss: 0.905753, time: 0.1s\n",
      "epoch 60, training loss: 0.846197, time: 0.1s\n",
      "epoch 70, training loss: 0.810715, time: 0.1s\n",
      "epoch 80, training loss: 0.743264, time: 0.1s\n",
      "epoch 90, training loss: 0.686449, time: 0.1s\n",
      "epoch100, training loss: 0.713195, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 36.340783, time: 0.1s\n",
      "epoch 10, training loss: 1.771345, time: 0.1s\n",
      "epoch 20, training loss: 1.277593, time: 0.1s\n",
      "epoch 30, training loss: 1.009374, time: 0.1s\n",
      "epoch 40, training loss: 0.939301, time: 0.1s\n",
      "epoch 50, training loss: 0.930740, time: 0.1s\n",
      "epoch 60, training loss: 0.801810, time: 0.1s\n",
      "epoch 70, training loss: 0.846673, time: 0.1s\n",
      "epoch 80, training loss: 0.733163, time: 0.1s\n",
      "epoch 90, training loss: 0.694137, time: 0.1s\n",
      "epoch100, training loss: 0.683217, time: 0.1s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 28.128756, time: 0.1s\n",
      "epoch 10, training loss: 1.482297, time: 0.1s\n",
      "epoch 20, training loss: 1.089636, time: 0.1s\n",
      "epoch 30, training loss: 1.012150, time: 0.1s\n",
      "epoch 40, training loss: 0.944334, time: 0.1s\n",
      "epoch 50, training loss: 0.896048, time: 0.1s\n",
      "epoch 60, training loss: 0.846152, time: 0.1s\n",
      "epoch 70, training loss: 0.808572, time: 0.1s\n",
      "epoch 80, training loss: 0.787940, time: 0.1s\n",
      "epoch 90, training loss: 0.753720, time: 0.1s\n",
      "epoch100, training loss: 0.710180, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 16/16 [00:00<00:00, 422.13it/s]\n",
      "testing: 100%|██████████| 16/16 [00:00<00:00, 406.84it/s]\n",
      "testing: 100%|██████████| 16/16 [00:00<00:00, 405.71it/s]\n",
      "testing: 100%|██████████| 16/16 [00:00<00:00, 402.56it/s]\n",
      "testing: 100%|██████████| 16/16 [00:00<00:00, 388.71it/s]\n",
      "testing: 100%|██████████| 16/16 [00:00<00:00, 374.56it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 368.18it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 375.15it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 374.38it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 361.28it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 334.58it/s]\n",
      "testing: 100%|██████████| 7/7 [00:00<00:00, 383.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current noise type: None\n",
      "{'Samples': 3772, 'Features': 6, 'Anomalies': 93, 'Anomalies Ratio(%)': 2.47}\n",
      "best param: None\n",
      "Start Training...\n",
      "ensemble size: 8\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 29.218465, time: 0.3s\n",
      "epoch 10, training loss: 0.901963, time: 0.3s\n",
      "epoch 20, training loss: 0.484374, time: 0.3s\n",
      "epoch 30, training loss: 0.369372, time: 0.3s\n",
      "epoch 40, training loss: 0.388006, time: 0.3s\n",
      "epoch 50, training loss: 0.305867, time: 0.3s\n",
      "epoch 60, training loss: 0.263801, time: 0.3s\n",
      "epoch 70, training loss: 0.268020, time: 0.3s\n",
      "epoch 80, training loss: 0.270495, time: 0.3s\n",
      "epoch 90, training loss: 0.236442, time: 0.2s\n",
      "epoch100, training loss: 0.326870, time: 0.3s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 19.193649, time: 0.3s\n",
      "epoch 10, training loss: 0.702553, time: 0.3s\n",
      "epoch 20, training loss: 0.393976, time: 0.3s\n",
      "epoch 30, training loss: 0.304987, time: 0.3s\n",
      "epoch 40, training loss: 0.349018, time: 0.3s\n",
      "epoch 50, training loss: 0.357506, time: 0.3s\n",
      "epoch 60, training loss: 0.279786, time: 0.3s\n",
      "epoch 70, training loss: 0.222097, time: 0.3s\n",
      "epoch 80, training loss: 0.242448, time: 0.3s\n",
      "epoch 90, training loss: 0.236310, time: 0.3s\n",
      "epoch100, training loss: 0.205595, time: 0.3s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 25.089684, time: 0.2s\n",
      "epoch 10, training loss: 0.900525, time: 0.3s\n",
      "epoch 20, training loss: 0.473303, time: 0.3s\n",
      "epoch 30, training loss: 0.405150, time: 0.3s\n",
      "epoch 40, training loss: 0.351408, time: 0.3s\n",
      "epoch 50, training loss: 0.357196, time: 0.3s\n",
      "epoch 60, training loss: 0.310211, time: 0.3s\n",
      "epoch 70, training loss: 0.277882, time: 0.3s\n",
      "epoch 80, training loss: 0.249741, time: 0.3s\n",
      "epoch 90, training loss: 0.221648, time: 0.3s\n",
      "epoch100, training loss: 0.229024, time: 0.3s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 36.904547, time: 0.3s\n",
      "epoch 10, training loss: 1.104519, time: 0.3s\n",
      "epoch 20, training loss: 0.607233, time: 0.3s\n",
      "epoch 30, training loss: 0.453211, time: 0.3s\n",
      "epoch 40, training loss: 0.424869, time: 0.3s\n",
      "epoch 50, training loss: 0.385977, time: 0.3s\n",
      "epoch 60, training loss: 0.357614, time: 0.3s\n",
      "epoch 70, training loss: 0.294661, time: 0.3s\n",
      "epoch 80, training loss: 0.334352, time: 0.3s\n",
      "epoch 90, training loss: 0.266011, time: 0.3s\n",
      "epoch100, training loss: 0.230215, time: 0.3s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 19.757167, time: 0.3s\n",
      "epoch 10, training loss: 0.770969, time: 0.3s\n",
      "epoch 20, training loss: 0.470639, time: 0.3s\n",
      "epoch 30, training loss: 0.346924, time: 0.3s\n",
      "epoch 40, training loss: 0.304493, time: 0.3s\n",
      "epoch 50, training loss: 0.312785, time: 0.3s\n",
      "epoch 60, training loss: 0.284431, time: 0.3s\n",
      "epoch 70, training loss: 0.242187, time: 0.3s\n",
      "epoch 80, training loss: 0.248984, time: 0.2s\n",
      "epoch 90, training loss: 0.239625, time: 0.3s\n",
      "epoch100, training loss: 0.219735, time: 0.3s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 17.717220, time: 0.3s\n",
      "epoch 10, training loss: 0.948056, time: 0.3s\n",
      "epoch 20, training loss: 0.498522, time: 0.3s\n",
      "epoch 30, training loss: 0.601816, time: 0.2s\n",
      "epoch 40, training loss: 0.351720, time: 0.3s\n",
      "epoch 50, training loss: 0.283096, time: 0.3s\n",
      "epoch 60, training loss: 0.268995, time: 0.3s\n",
      "epoch 70, training loss: 0.263044, time: 0.3s\n",
      "epoch 80, training loss: 0.363474, time: 0.2s\n",
      "epoch 90, training loss: 0.270429, time: 0.3s\n",
      "epoch100, training loss: 0.245085, time: 0.3s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 16.892329, time: 0.3s\n",
      "epoch 10, training loss: 0.936685, time: 0.3s\n",
      "epoch 20, training loss: 0.465903, time: 0.3s\n",
      "epoch 30, training loss: 0.406803, time: 0.3s\n",
      "epoch 40, training loss: 0.326253, time: 0.3s\n",
      "epoch 50, training loss: 0.315352, time: 0.3s\n",
      "epoch 60, training loss: 0.336152, time: 0.3s\n",
      "epoch 70, training loss: 0.268782, time: 0.3s\n",
      "epoch 80, training loss: 0.223738, time: 0.3s\n",
      "epoch 90, training loss: 0.238991, time: 0.3s\n",
      "epoch100, training loss: 0.226280, time: 0.3s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=4, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 21.067305, time: 0.3s\n",
      "epoch 10, training loss: 0.737990, time: 0.3s\n",
      "epoch 20, training loss: 0.385057, time: 0.3s\n",
      "epoch 30, training loss: 0.329420, time: 0.3s\n",
      "epoch 40, training loss: 0.295736, time: 0.3s\n",
      "epoch 50, training loss: 0.328127, time: 0.3s\n",
      "epoch 60, training loss: 0.231093, time: 0.3s\n",
      "epoch 70, training loss: 0.239335, time: 0.3s\n",
      "epoch 80, training loss: 0.238083, time: 0.3s\n",
      "epoch 90, training loss: 0.222905, time: 0.3s\n",
      "epoch100, training loss: 0.205139, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 42/42 [00:00<00:00, 375.41it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 356.63it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 365.61it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 358.27it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 364.63it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 366.74it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 380.62it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 360.29it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 380.76it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 345.04it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 377.77it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 358.87it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 373.48it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 359.61it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 419.20it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 476.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1, training loss: 21.067305, time: 0.3s\n",
      "epoch 10, training loss: 0.737990, time: 0.3s\n",
      "epoch 20, training loss: 0.385057, time: 0.2s\n",
      "epoch 30, training loss: 0.329420, time: 0.3s\n",
      "epoch 40, training loss: 0.295736, time: 0.2s\n",
      "epoch 50, training loss: 0.328127, time: 0.3s\n",
      "epoch 60, training loss: 0.231093, time: 0.2s\n",
      "epoch 70, training loss: 0.239335, time: 0.2s\n",
      "epoch 80, training loss: 0.238083, time: 0.2s\n",
      "epoch 90, training loss: 0.222905, time: 0.3s\n",
      "epoch100, training loss: 0.205139, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 42/42 [00:00<00:00, 445.48it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 453.10it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 446.89it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 429.05it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 457.34it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 396.37it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 453.05it/s]\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 449.25it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 416.00it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 389.63it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 383.69it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 360.23it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 356.11it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 410.97it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 396.25it/s]\n",
      "testing: 100%|██████████| 18/18 [00:00<00:00, 427.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# seed for reproducible results\n",
    "seed = 42\n",
    "\n",
    "for dataset in dataset_list:\n",
    "    datagenerator.dataset = dataset  # specify the dataset name\n",
    "    data = datagenerator.generator(\n",
    "        la=0.1, realistic_synthetic_mode=None, noise_type=None\n",
    "    )  # only 10% labeled anomalies are available\n",
    "\n",
    "    for name, model_cls in model_dict.items():\n",
    "        # model initialization\n",
    "        model = model_cls(seed=seed, model_name=name)\n",
    "\n",
    "        # training, for unsupervised models the y label will be discarded\n",
    "        model = model.fit(X_train=data[\"X_train\"], y_train=data[\"y_train\"])\n",
    "\n",
    "        # output predicted anomaly score on testing set\n",
    "        score = model.predict_score(data[\"X_test\"])\n",
    "\n",
    "        # evaluation\n",
    "        result = utils.metric(y_true=data[\"y_test\"], y_score=score)\n",
    "\n",
    "        # save results\n",
    "        df_AUCROC.loc[dataset, name] = result[\"aucroc\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-brain",
   "metadata": {},
   "source": [
    "## Metrics and Results \n",
    "The Area Under the Receiver Operating Characteristic (AUROC) curve is a fundamental metric used to evaluate the performance of anomaly detection models. It provides insight into how well a model can distinguish between normal and anomalous instances across various threshold settings. AUC represents the degree or measure of separability calculated using ROC curves. It indicates how well the model can distinguish between classes. The higher the AUC, the better the model predicts 0 classes as 0 and 1 classes as 1. Below is a table that shows AUCROC values for different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cognitive-shape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6_cardio</th>\n",
       "      <td>0.793364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_fraud</th>\n",
       "      <td>0.867379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24_mnist</th>\n",
       "      <td>0.892911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42_WBC</th>\n",
       "      <td>0.952828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43_WDBC</th>\n",
       "      <td>0.974138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_breastw</th>\n",
       "      <td>0.826051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25_musk</th>\n",
       "      <td>0.999109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40_vowels</th>\n",
       "      <td>0.850237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38_thyroid</th>\n",
       "      <td>0.864163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ICL\n",
       "6_cardio    0.793364\n",
       "13_fraud    0.867379\n",
       "24_mnist    0.892911\n",
       "42_WBC      0.952828\n",
       "43_WDBC     0.974138\n",
       "4_breastw   0.826051\n",
       "25_musk     0.999109\n",
       "40_vowels   0.850237\n",
       "38_thyroid  0.864163"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AUCROC  # noqa: B018\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl_env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
